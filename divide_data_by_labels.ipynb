{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "from scipy.interpolate import interp1d\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = './models/activity_estimator_both_study_magnitude_final_5_labels.hdf5'\n",
    "model = load_model(model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pickle.load(open('./data/mORAL_dataset_for_python_upload_09072020/processed_data/all_data_right_wrist.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_acl(a,window_size=20,fs_now=25,fs_new=20):\n",
    "    x_now = np.linspace(0,window_size,a.shape[0])\n",
    "    f = interp1d(x_now,a,axis=0,fill_value='extrapolate')\n",
    "    x_new = np.linspace(0,window_size,window_size*fs_new)\n",
    "    return f(x_new)\n",
    "\n",
    "def get_magnitude_array(a):\n",
    "    a = a[a[:,0].argsort()]\n",
    "    magnitude_array = np.sqrt(np.square(a[:,1])+np.square(a[:,2])+np.square(a[:,3])).reshape(-1,1)\n",
    "    magnitude_interpolated_array = interpolate_acl(magnitude_array)\n",
    "    return magnitude_interpolated_array\n",
    "\n",
    "all_data['magnitude'] = all_data['data'].apply(lambda a:get_magnitude_array(a).reshape(1,-1,1))\n",
    "all_data = all_data.sort_values('timestamp').reset_index(drop=True)\n",
    "X = np.concatenate(list(all_data['magnitude'].values))\n",
    "prediction = model.predict(X).argmax(axis=1)\n",
    "all_data['prediction'] = prediction\n",
    "# final_activity_list = ['Stationery','Stairs','Exercise','Walking','Sports']\n",
    "final_activity_list = ['Stationery','Walking','Exercise','Walking','Sports']\n",
    "all_data['prediction'] = all_data['prediction'].apply(lambda a:final_activity_list[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = all_data.groupby('user',as_index=False).count().sort_values('timestamp',ascending=False).reset_index(drop=True)[:-2]['user'].values\n",
    "all_data = all_data[all_data.user.isin(users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   4 | elapsed:   18.2s remaining:   18.2s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  1.7min finished\n"
     ]
    }
   ],
   "source": [
    "def interpolate_all_data(a):\n",
    "    a = a[a[:,0].argsort()]\n",
    "    a = a[:,1:].reshape(-1,3)\n",
    "    a = interpolate_acl(a,fs_new=25)\n",
    "    return a.reshape(1,-1,3)\n",
    "\n",
    "\n",
    "def get_data(df,split_type='train',train_split = 0.8):\n",
    "    df = df.sort_values('timestamp').reset_index(drop=True)\n",
    "    if split_type=='train':\n",
    "        df = df.iloc[:int(train_split*df.shape[0])]\n",
    "    else:\n",
    "        df = df.iloc[int(train_split*df.shape[0]):]\n",
    "    return df\n",
    "\n",
    "def save_data_by_labels(df):\n",
    "    activity = df['prediction'].values[0]\n",
    "    if not os.path.isdir(os.path.join(data_directory,activity)):\n",
    "        os.makedirs(os.path.join(data_directory,activity))\n",
    "    df['final_data'] = df['data'].apply(lambda a:interpolate_all_data(a))\n",
    "    train_data = pd.concat([get_data(df_user,split_type='train') for j,df_user in df.groupby('user',as_index=False)]).sort_values('timestamp').reset_index(drop=True)\n",
    "    train_path = os.path.join(data_directory,activity,'train.p')\n",
    "    pickle.dump(train_data,open(train_path,'wb'))\n",
    "    test_data = pd.concat([get_data(df_user,split_type='test') for j,df_user in df.groupby('user',as_index=False)]).sort_values('timestamp').reset_index(drop=True)\n",
    "    test_path = os.path.join(data_directory,activity,'test.p')\n",
    "    pickle.dump(test_data,open(test_path,'wb'))\n",
    "    print(activity,train_data.shape,test_data.shape)\n",
    "    return activity,train_data.shape,test_data.shape\n",
    "\n",
    "data_directory = './data/mORAL_dataset_for_python_upload_09072020/processed_data/'\n",
    "done = Parallel(n_jobs=-1,verbose=2)(delayed(save_data_by_labels)(df) for i,df in all_data.groupby('prediction',as_index=False))   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Exercise', (244, 8), (71, 8)),\n",
       " ('Sports', (40782, 8), (10204, 8)),\n",
       " ('Stationery', (286619, 8), (71662, 8)),\n",
       " ('Walking', (15871, 8), (3976, 8))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51b244ab9aca612e739a0539ae1af887c58db9e180d786deb0ab1761def69c1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
