{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow_addons.losses import metric_learning\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras import backend as K\n",
    "import pickle\n",
    "import os\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "gpu_id = 1\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "# Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[gpu_id], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "def _pairwise_distances(feature_A, feature_B=None, squared=False):\n",
    "    \"\"\"\n",
    "    Directly from https://www.tensorflow.org/api_docs/python/tf/contrib/losses/metric_learning/triplet_semihard_loss\n",
    "    Computes the pairwise distance matrix with numerical stability.\n",
    "    output[i, j] = || feature[i, :] - feature[j, :] ||_2\n",
    "    Args:\n",
    "      feature_A: 2-D Tensor of size [number of data A, feature dimension].\n",
    "      feature_B: 2-D Tensor of size [number of data B, feature dimension].\n",
    "      squared: Boolean, whether or not to square the pairwise distances.\n",
    "    Returns:\n",
    "      pairwise_distances: 2-D Tensor of size [number of data A, number of data B].\n",
    "    \"\"\"\n",
    "    if feature_B is None:\n",
    "        feature_B = feature_A\n",
    "\n",
    "    pairwise_distances_squared = tf.add(\n",
    "        tf.reduce_sum(tf.square(feature_A), axis=[1], keepdims=True),\n",
    "        tf.reduce_sum(tf.square(tf.transpose(feature_B)), axis=[0], keepdims=True),\n",
    "    ) - 2.0 * tf.linalg.matmul(feature_A, tf.transpose(feature_B))\n",
    "\n",
    "    # Deal with numerical inaccuracies. Set small negatives to zero.\n",
    "    pairwise_distances_squared = tf.maximum(pairwise_distances_squared, 0.0)\n",
    "    # Get the mask where the zero distances are at.\n",
    "    error_mask = tf.less_equal(pairwise_distances_squared, 0.0)\n",
    "\n",
    "    # Optionally take the sqrt.\n",
    "    if squared:\n",
    "        pairwise_distances = pairwise_distances_squared\n",
    "    else:\n",
    "        pairwise_distances = tf.sqrt(\n",
    "            pairwise_distances_squared + tf.cast(error_mask, tf.float32) * 1e-16\n",
    "        )\n",
    "\n",
    "    # Undo conditionally adding 1e-16.\n",
    "    pairwise_distances = tf.multiply(\n",
    "        pairwise_distances, tf.cast(tf.logical_not(error_mask), tf.float32)\n",
    "    )\n",
    "\n",
    "    if feature_B is None:\n",
    "        num_data = tf.shape(feature_A)[0]\n",
    "        # Explicitly set diagonals to zero.\n",
    "        mask_offdiagonals = tf.ones_like(pairwise_distances) - tf.linalg.diag(\n",
    "            tf.ones([num_data])\n",
    "        )\n",
    "        pairwise_distances = tf.multiply(pairwise_distances, mask_offdiagonals)\n",
    "\n",
    "    return pairwise_distances\n",
    "def get_consistency_distinction_loss(labels,embeddings):\n",
    "    epsilon = 1e-7\n",
    "    lshape = tf.shape(labels)\n",
    "    labels = tf.reshape(labels, [lshape[0], 1])\n",
    "    clusters_labels, _, num_embeddings_per_cluster = tf.unique_with_counts(\n",
    "        tf.reshape(labels, [lshape[0]])\n",
    "        )    \n",
    "    num_clusters = tf.size(clusters_labels)\n",
    "    adjacency = tf.equal(\n",
    "        labels, tf.transpose(clusters_labels)\n",
    "    )  \n",
    "    centroids = tf.linalg.matmul(\n",
    "        tf.cast(adjacency, dtype=tf.float32), embeddings, transpose_a=True\n",
    "    )\n",
    "    centroids = tf.divide(\n",
    "        centroids,\n",
    "        tf.expand_dims(tf.cast(num_embeddings_per_cluster, dtype=tf.float32), axis=1),\n",
    "    )\n",
    "    pairwise_distances_distinction_first = _pairwise_distances(\n",
    "        feature_A=embeddings, feature_B=centroids, squared=True\n",
    "    )\n",
    "    pairwise_distances_distinction_first = pairwise_distances_distinction_first/tf.reshape(tf.reduce_max(pairwise_distances_distinction_first,axis=1),[lshape[0],1])\n",
    "    adjacency_not = tf.logical_not(adjacency)\n",
    "    pairwise_distances_distinction = tf.where(tf.cast(adjacency,tf.float32)==1.0,tf.reduce_max(pairwise_distances_distinction_first),pairwise_distances_distinction_first)\n",
    "    minimum_distance_to_other_cluster = tf.reduce_min(pairwise_distances_distinction,axis=1)\n",
    "    distinction_loss = tf.reduce_mean(minimum_distance_to_other_cluster)\n",
    "    mean_intra_class_distance = tf.reduce_mean(tf.boolean_mask(pairwise_distances_distinction_first,adjacency))\n",
    "    mean_inter_class_distance = tf.reduce_mean(tf.boolean_mask(pairwise_distances_distinction_first,tf.logical_not(adjacency)))\n",
    "    alpha = mean_intra_class_distance/ (mean_inter_class_distance+epsilon)\n",
    "    \n",
    "    \n",
    "    ## If mean is used as aggregation\n",
    "    pairwise_distances_distinction_first = tf.multiply(pairwise_distances_distinction_first, tf.cast(adjacency,tf.float32))\n",
    "    mean_distance_same_class = tf.reduce_max(pairwise_distances_distinction_first,axis=1)\n",
    "    consistency_loss = tf.reduce_mean(mean_distance_same_class)\n",
    "    \n",
    "    \n",
    "    ## If percentile is used as aggregation\n",
    "    # pairwise_distances_distinction_first = tf.multiply(pairwise_distances_distinction_first, tf.cast(adjacency,tf.float32))\n",
    "    # mean_distance_same_class = tf.reduce_max(pairwise_distances_distinction_first,axis=1)\n",
    "    # loss = tf.constant(0,dtype=tf.float32)\n",
    "    # for label in clusters_labels:\n",
    "    #     percentile_95 = tfp.stats.percentile(tf.where(labels==label,mean_distance_same_class,tf.reduce_max(mean_distance_same_class)),95)\n",
    "    #     loss+=percentile_95\n",
    "    # consistency_loss = loss/tf.cast(tf.size(clusters_labels),tf.float32)\n",
    "    \n",
    "    return  (1+alpha)*consistency_loss - distinction_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = tf.convert_to_tensor(np.random.randn(10,100),dtype=tf.float32)\n",
    "# labels = tf.convert_to_tensor(np.random.randint(0,4,10),dtype=tf.float32)\n",
    "# mask_for_equal = tf.math.equal(labels,tf.transpose(labels))\n",
    "# pairwise_distances = _pairwise_distances(embeddings,squared=True)\n",
    "# pairwise_distances = pairwise_distances/tf.reshape(tf.reduce_max(pairwise_distances,axis=1),[lshape[0],1])    \n",
    "# pairwise_distance_for_consistency  = tf.multiply(pairwise_distances, tf.cast(mask_for_equal,tf.float32))\n",
    "# counts_same_class = tf.reduce_sum(tf.cast(mask_for_equal,tf.float32),axis=1)\n",
    "# total_distance_same_class = tf.reduce_sum(pairwise_distance_for_consistency,axis=1)\n",
    "# mean_distance_same_class = total_distance_same_class/(counts_same_class-1+epsilon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "25/25 [==============================] - 4s 64ms/step - loss: 15.2904 - final_loss: 3.0012 - feature_loss: 0.2843 - final_acc: 0.1139 - val_loss: 15.0631 - val_final_loss: 2.9640 - val_feature_loss: 0.2430 - val_final_acc: 0.1325\n",
      "\n",
      "Epoch 00001: val_final_acc improved from -inf to 0.13254, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 2/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 14.9409 - final_loss: 2.9454 - feature_loss: 0.2138 - final_acc: 0.1657 - val_loss: 15.0067 - val_final_loss: 2.9468 - val_feature_loss: 0.2727 - val_final_acc: 0.1486\n",
      "\n",
      "Epoch 00002: val_final_acc improved from 0.13254 to 0.14859, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 3/2000\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 14.7450 - final_loss: 2.9036 - feature_loss: 0.2268 - final_acc: 0.1988 - val_loss: 15.0608 - val_final_loss: 2.9511 - val_feature_loss: 0.3055 - val_final_acc: 0.1213\n",
      "\n",
      "Epoch 00003: val_final_acc did not improve from 0.14859\n",
      "Epoch 4/2000\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 14.5827 - final_loss: 2.8740 - feature_loss: 0.2129 - final_acc: 0.2144 - val_loss: 14.9498 - val_final_loss: 2.9349 - val_feature_loss: 0.2755 - val_final_acc: 0.1059\n",
      "\n",
      "Epoch 00004: val_final_acc did not improve from 0.14859\n",
      "Epoch 5/2000\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 14.4439 - final_loss: 2.8433 - feature_loss: 0.2273 - final_acc: 0.2315 - val_loss: 14.9633 - val_final_loss: 2.9275 - val_feature_loss: 0.3258 - val_final_acc: 0.1220\n",
      "\n",
      "Epoch 00005: val_final_acc did not improve from 0.14859\n",
      "Epoch 6/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 14.2641 - final_loss: 2.8110 - feature_loss: 0.2093 - final_acc: 0.2430 - val_loss: 14.8201 - val_final_loss: 2.9044 - val_feature_loss: 0.2981 - val_final_acc: 0.1573\n",
      "\n",
      "Epoch 00006: val_final_acc improved from 0.14859 to 0.15725, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 7/2000\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 14.0925 - final_loss: 2.7795 - feature_loss: 0.1948 - final_acc: 0.2447 - val_loss: 14.7077 - val_final_loss: 2.8794 - val_feature_loss: 0.3107 - val_final_acc: 0.1473\n",
      "\n",
      "Epoch 00007: val_final_acc did not improve from 0.15725\n",
      "Epoch 8/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 14.0315 - final_loss: 2.7722 - feature_loss: 0.1705 - final_acc: 0.2524 - val_loss: 14.4179 - val_final_loss: 2.8319 - val_feature_loss: 0.2582 - val_final_acc: 0.1672\n",
      "\n",
      "Epoch 00008: val_final_acc improved from 0.15725 to 0.16720, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 9/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 13.6884 - final_loss: 2.7088 - feature_loss: 0.1441 - final_acc: 0.2695 - val_loss: 14.2269 - val_final_loss: 2.7891 - val_feature_loss: 0.2814 - val_final_acc: 0.2051\n",
      "\n",
      "Epoch 00009: val_final_acc improved from 0.16720 to 0.20507, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 10/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 13.4814 - final_loss: 2.6691 - feature_loss: 0.1359 - final_acc: 0.2944 - val_loss: 14.0044 - val_final_loss: 2.7506 - val_feature_loss: 0.2513 - val_final_acc: 0.2192\n",
      "\n",
      "Epoch 00010: val_final_acc improved from 0.20507 to 0.21919, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 11/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 13.2302 - final_loss: 2.6219 - feature_loss: 0.1206 - final_acc: 0.3104 - val_loss: 14.1477 - val_final_loss: 2.7816 - val_feature_loss: 0.2394 - val_final_acc: 0.2112\n",
      "\n",
      "Epoch 00011: val_final_acc did not improve from 0.21919\n",
      "Epoch 12/2000\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 12.9889 - final_loss: 2.5758 - feature_loss: 0.1097 - final_acc: 0.3282 - val_loss: 13.7263 - val_final_loss: 2.6973 - val_feature_loss: 0.2401 - val_final_acc: 0.2436\n",
      "\n",
      "Epoch 00012: val_final_acc improved from 0.21919 to 0.24358, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 13/2000\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 12.7889 - final_loss: 2.5372 - feature_loss: 0.1030 - final_acc: 0.3486 - val_loss: 14.1259 - val_final_loss: 2.7758 - val_feature_loss: 0.2470 - val_final_acc: 0.2064\n",
      "\n",
      "Epoch 00013: val_final_acc did not improve from 0.24358\n",
      "Epoch 14/2000\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 12.6104 - final_loss: 2.5006 - feature_loss: 0.1072 - final_acc: 0.3549 - val_loss: 13.4045 - val_final_loss: 2.6338 - val_feature_loss: 0.2356 - val_final_acc: 0.2612\n",
      "\n",
      "Epoch 00014: val_final_acc improved from 0.24358 to 0.26123, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 15/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 12.3789 - final_loss: 2.4566 - feature_loss: 0.0961 - final_acc: 0.3820 - val_loss: 12.8891 - val_final_loss: 2.5434 - val_feature_loss: 0.1721 - val_final_acc: 0.2936\n",
      "\n",
      "Epoch 00015: val_final_acc improved from 0.26123 to 0.29365, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 16/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 12.1753 - final_loss: 2.4174 - feature_loss: 0.0883 - final_acc: 0.3888 - val_loss: 12.6797 - val_final_loss: 2.5032 - val_feature_loss: 0.1639 - val_final_acc: 0.3145\n",
      "\n",
      "Epoch 00016: val_final_acc improved from 0.29365 to 0.31451, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 17/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 11.9953 - final_loss: 2.3820 - feature_loss: 0.0851 - final_acc: 0.3998 - val_loss: 12.7163 - val_final_loss: 2.5076 - val_feature_loss: 0.1783 - val_final_acc: 0.3049\n",
      "\n",
      "Epoch 00017: val_final_acc did not improve from 0.31451\n",
      "Epoch 18/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 11.7841 - final_loss: 2.3413 - feature_loss: 0.0778 - final_acc: 0.4128 - val_loss: 12.2816 - val_final_loss: 2.4290 - val_feature_loss: 0.1364 - val_final_acc: 0.3235\n",
      "\n",
      "Epoch 00018: val_final_acc improved from 0.31451 to 0.32349, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 19/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 11.6344 - final_loss: 2.3106 - feature_loss: 0.0815 - final_acc: 0.4178 - val_loss: 12.2057 - val_final_loss: 2.4100 - val_feature_loss: 0.1555 - val_final_acc: 0.3501\n",
      "\n",
      "Epoch 00019: val_final_acc improved from 0.32349 to 0.35013, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 20/2000\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 11.5031 - final_loss: 2.2847 - feature_loss: 0.0798 - final_acc: 0.4231 - val_loss: 12.0139 - val_final_loss: 2.3748 - val_feature_loss: 0.1397 - val_final_acc: 0.3498\n",
      "\n",
      "Epoch 00020: val_final_acc did not improve from 0.35013\n",
      "Epoch 21/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 11.2836 - final_loss: 2.2430 - feature_loss: 0.0687 - final_acc: 0.4448 - val_loss: 11.5002 - val_final_loss: 2.2801 - val_feature_loss: 0.1000 - val_final_acc: 0.4024\n",
      "\n",
      "Epoch 00021: val_final_acc improved from 0.35013 to 0.40244, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 22/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 11.0867 - final_loss: 2.2053 - feature_loss: 0.0601 - final_acc: 0.4482 - val_loss: 11.4815 - val_final_loss: 2.2751 - val_feature_loss: 0.1057 - val_final_acc: 0.3925\n",
      "\n",
      "Epoch 00022: val_final_acc did not improve from 0.40244\n",
      "Epoch 23/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 10.9521 - final_loss: 2.1781 - feature_loss: 0.0615 - final_acc: 0.4568 - val_loss: 11.4569 - val_final_loss: 2.2659 - val_feature_loss: 0.1276 - val_final_acc: 0.3970\n",
      "\n",
      "Epoch 00023: val_final_acc did not improve from 0.40244\n",
      "Epoch 24/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 10.8456 - final_loss: 2.1564 - feature_loss: 0.0637 - final_acc: 0.4504 - val_loss: 11.1352 - val_final_loss: 2.2061 - val_feature_loss: 0.1045 - val_final_acc: 0.4069\n",
      "\n",
      "Epoch 00024: val_final_acc improved from 0.40244 to 0.40693, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 25/2000\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 10.5812 - final_loss: 2.1067 - feature_loss: 0.0478 - final_acc: 0.4755 - val_loss: 10.9198 - val_final_loss: 2.1660 - val_feature_loss: 0.0898 - val_final_acc: 0.4349\n",
      "\n",
      "Epoch 00025: val_final_acc improved from 0.40693 to 0.43485, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 26/2000\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 10.5055 - final_loss: 2.0907 - feature_loss: 0.0522 - final_acc: 0.4757 - val_loss: 10.8161 - val_final_loss: 2.1453 - val_feature_loss: 0.0895 - val_final_acc: 0.4272\n",
      "\n",
      "Epoch 00026: val_final_acc did not improve from 0.43485\n",
      "Epoch 27/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 10.3816 - final_loss: 2.0665 - feature_loss: 0.0492 - final_acc: 0.4837 - val_loss: 10.7017 - val_final_loss: 2.1244 - val_feature_loss: 0.0794 - val_final_acc: 0.4419\n",
      "\n",
      "Epoch 00027: val_final_acc improved from 0.43485 to 0.44191, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 28/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 10.1894 - final_loss: 2.0294 - feature_loss: 0.0422 - final_acc: 0.4901 - val_loss: 10.6026 - val_final_loss: 2.1026 - val_feature_loss: 0.0895 - val_final_acc: 0.4509\n",
      "\n",
      "Epoch 00028: val_final_acc improved from 0.44191 to 0.45090, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 29/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 10.0596 - final_loss: 2.0033 - feature_loss: 0.0431 - final_acc: 0.4904 - val_loss: 10.6863 - val_final_loss: 2.1202 - val_feature_loss: 0.0854 - val_final_acc: 0.4262\n",
      "\n",
      "Epoch 00029: val_final_acc did not improve from 0.45090\n",
      "Epoch 30/2000\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 9.9651 - final_loss: 1.9864 - feature_loss: 0.0331 - final_acc: 0.5020 - val_loss: 10.2521 - val_final_loss: 2.0366 - val_feature_loss: 0.0690 - val_final_acc: 0.4605\n",
      "\n",
      "Epoch 00030: val_final_acc improved from 0.45090 to 0.46053, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 31/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 9.7278 - final_loss: 1.9399 - feature_loss: 0.0280 - final_acc: 0.5169 - val_loss: 10.3780 - val_final_loss: 2.0601 - val_feature_loss: 0.0773 - val_final_acc: 0.4409\n",
      "\n",
      "Epoch 00031: val_final_acc did not improve from 0.46053\n",
      "Epoch 32/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 9.6547 - final_loss: 1.9258 - feature_loss: 0.0256 - final_acc: 0.5159 - val_loss: 10.1814 - val_final_loss: 2.0211 - val_feature_loss: 0.0759 - val_final_acc: 0.4592\n",
      "\n",
      "Epoch 00032: val_final_acc did not improve from 0.46053\n",
      "Epoch 33/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 9.4107 - final_loss: 1.8786 - feature_loss: 0.0175 - final_acc: 0.5361 - val_loss: 9.8600 - val_final_loss: 1.9615 - val_feature_loss: 0.0523 - val_final_acc: 0.4949\n",
      "\n",
      "Epoch 00033: val_final_acc improved from 0.46053 to 0.49487, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 34/2000\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 9.2396 - final_loss: 1.8457 - feature_loss: 0.0109 - final_acc: 0.5501 - val_loss: 9.9099 - val_final_loss: 1.9678 - val_feature_loss: 0.0708 - val_final_acc: 0.4788\n",
      "\n",
      "Epoch 00034: val_final_acc did not improve from 0.49487\n",
      "Epoch 35/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 9.1651 - final_loss: 1.8304 - feature_loss: 0.0129 - final_acc: 0.5475 - val_loss: 9.8637 - val_final_loss: 1.9592 - val_feature_loss: 0.0679 - val_final_acc: 0.4766\n",
      "\n",
      "Epoch 00035: val_final_acc did not improve from 0.49487\n",
      "Epoch 36/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 8.9642 - final_loss: 1.7914 - feature_loss: 0.0074 - final_acc: 0.5522 - val_loss: 9.6167 - val_final_loss: 1.9121 - val_feature_loss: 0.0563 - val_final_acc: 0.4868\n",
      "\n",
      "Epoch 00036: val_final_acc did not improve from 0.49487\n",
      "Epoch 37/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 8.8060 - final_loss: 1.7608 - feature_loss: 0.0018 - final_acc: 0.5584 - val_loss: 9.3584 - val_final_loss: 1.8616 - val_feature_loss: 0.0502 - val_final_acc: 0.5058\n",
      "\n",
      "Epoch 00037: val_final_acc improved from 0.49487 to 0.50578, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 38/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 8.5902 - final_loss: 1.7189 - feature_loss: -0.0044 - final_acc: 0.5684 - val_loss: 9.4556 - val_final_loss: 1.8781 - val_feature_loss: 0.0652 - val_final_acc: 0.4884\n",
      "\n",
      "Epoch 00038: val_final_acc did not improve from 0.50578\n",
      "Epoch 39/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 8.4783 - final_loss: 1.6971 - feature_loss: -0.0073 - final_acc: 0.5750 - val_loss: 9.5344 - val_final_loss: 1.8918 - val_feature_loss: 0.0755 - val_final_acc: 0.4804\n",
      "\n",
      "Epoch 00039: val_final_acc did not improve from 0.50578\n",
      "Epoch 40/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 8.3294 - final_loss: 1.6685 - feature_loss: -0.0133 - final_acc: 0.5848 - val_loss: 9.2074 - val_final_loss: 1.8302 - val_feature_loss: 0.0565 - val_final_acc: 0.5093\n",
      "\n",
      "Epoch 00040: val_final_acc improved from 0.50578 to 0.50931, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 41/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 8.1966 - final_loss: 1.6427 - feature_loss: -0.0168 - final_acc: 0.5945 - val_loss: 9.0884 - val_final_loss: 1.8065 - val_feature_loss: 0.0557 - val_final_acc: 0.5164\n",
      "\n",
      "Epoch 00041: val_final_acc improved from 0.50931 to 0.51637, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 42/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 8.0098 - final_loss: 1.6066 - feature_loss: -0.0230 - final_acc: 0.6080 - val_loss: 8.9391 - val_final_loss: 1.7788 - val_feature_loss: 0.0449 - val_final_acc: 0.5279\n",
      "\n",
      "Epoch 00042: val_final_acc improved from 0.51637 to 0.52792, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 43/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 7.8178 - final_loss: 1.5702 - feature_loss: -0.0332 - final_acc: 0.6214 - val_loss: 8.7557 - val_final_loss: 1.7424 - val_feature_loss: 0.0438 - val_final_acc: 0.5388\n",
      "\n",
      "Epoch 00043: val_final_acc improved from 0.52792 to 0.53883, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 44/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 7.7056 - final_loss: 1.5473 - feature_loss: -0.0310 - final_acc: 0.6205 - val_loss: 9.0587 - val_final_loss: 1.7999 - val_feature_loss: 0.0593 - val_final_acc: 0.4984\n",
      "\n",
      "Epoch 00044: val_final_acc did not improve from 0.53883\n",
      "Epoch 45/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 7.6305 - final_loss: 1.5334 - feature_loss: -0.0367 - final_acc: 0.6270 - val_loss: 8.8022 - val_final_loss: 1.7505 - val_feature_loss: 0.0500 - val_final_acc: 0.5244\n",
      "\n",
      "Epoch 00045: val_final_acc did not improve from 0.53883\n",
      "Epoch 46/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 7.4269 - final_loss: 1.4935 - feature_loss: -0.0408 - final_acc: 0.6356 - val_loss: 8.6610 - val_final_loss: 1.7228 - val_feature_loss: 0.0468 - val_final_acc: 0.5353\n",
      "\n",
      "Epoch 00046: val_final_acc did not improve from 0.53883\n",
      "Epoch 47/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 7.3340 - final_loss: 1.4759 - feature_loss: -0.0453 - final_acc: 0.6464 - val_loss: 8.5768 - val_final_loss: 1.7070 - val_feature_loss: 0.0417 - val_final_acc: 0.5404\n",
      "\n",
      "Epoch 00047: val_final_acc improved from 0.53883 to 0.54044, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 48/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 7.1612 - final_loss: 1.4432 - feature_loss: -0.0547 - final_acc: 0.6551 - val_loss: 8.5143 - val_final_loss: 1.6942 - val_feature_loss: 0.0431 - val_final_acc: 0.5443\n",
      "\n",
      "Epoch 00048: val_final_acc improved from 0.54044 to 0.54429, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 49/2000\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 7.0275 - final_loss: 1.4175 - feature_loss: -0.0599 - final_acc: 0.6602 - val_loss: 8.5008 - val_final_loss: 1.6917 - val_feature_loss: 0.0425 - val_final_acc: 0.5411\n",
      "\n",
      "Epoch 00049: val_final_acc did not improve from 0.54429\n",
      "Epoch 50/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 6.8464 - final_loss: 1.3825 - feature_loss: -0.0661 - final_acc: 0.6784 - val_loss: 8.4662 - val_final_loss: 1.6844 - val_feature_loss: 0.0442 - val_final_acc: 0.5379\n",
      "\n",
      "Epoch 00050: val_final_acc did not improve from 0.54429\n",
      "Epoch 51/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 6.8747 - final_loss: 1.3865 - feature_loss: -0.0579 - final_acc: 0.6657 - val_loss: 8.2866 - val_final_loss: 1.6491 - val_feature_loss: 0.0411 - val_final_acc: 0.5565\n",
      "\n",
      "Epoch 00051: val_final_acc improved from 0.54429 to 0.55648, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 52/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 6.7110 - final_loss: 1.3557 - feature_loss: -0.0675 - final_acc: 0.6778 - val_loss: 8.2959 - val_final_loss: 1.6506 - val_feature_loss: 0.0427 - val_final_acc: 0.5453\n",
      "\n",
      "Epoch 00052: val_final_acc did not improve from 0.55648\n",
      "Epoch 53/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 6.6138 - final_loss: 1.3366 - feature_loss: -0.0695 - final_acc: 0.6809 - val_loss: 8.2784 - val_final_loss: 1.6470 - val_feature_loss: 0.0433 - val_final_acc: 0.5401\n",
      "\n",
      "Epoch 00053: val_final_acc did not improve from 0.55648\n",
      "Epoch 54/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 6.4711 - final_loss: 1.3090 - feature_loss: -0.0736 - final_acc: 0.6880 - val_loss: 8.2038 - val_final_loss: 1.6326 - val_feature_loss: 0.0410 - val_final_acc: 0.5510\n",
      "\n",
      "Epoch 00054: val_final_acc did not improve from 0.55648\n",
      "Epoch 55/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 6.2798 - final_loss: 1.2734 - feature_loss: -0.0873 - final_acc: 0.6988 - val_loss: 8.0566 - val_final_loss: 1.6048 - val_feature_loss: 0.0325 - val_final_acc: 0.5661\n",
      "\n",
      "Epoch 00055: val_final_acc improved from 0.55648 to 0.56611, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 56/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 6.1557 - final_loss: 1.2494 - feature_loss: -0.0912 - final_acc: 0.7119 - val_loss: 8.2158 - val_final_loss: 1.6338 - val_feature_loss: 0.0466 - val_final_acc: 0.5507\n",
      "\n",
      "Epoch 00056: val_final_acc did not improve from 0.56611\n",
      "Epoch 57/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 6.0378 - final_loss: 1.2264 - feature_loss: -0.0943 - final_acc: 0.7128 - val_loss: 8.0688 - val_final_loss: 1.6053 - val_feature_loss: 0.0421 - val_final_acc: 0.5613\n",
      "\n",
      "Epoch 00057: val_final_acc did not improve from 0.56611\n",
      "Epoch 58/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 6.0797 - final_loss: 1.2339 - feature_loss: -0.0899 - final_acc: 0.7075 - val_loss: 7.9364 - val_final_loss: 1.5804 - val_feature_loss: 0.0346 - val_final_acc: 0.5623\n",
      "\n",
      "Epoch 00058: val_final_acc did not improve from 0.56611\n",
      "Epoch 59/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 5.8112 - final_loss: 1.1825 - feature_loss: -0.1013 - final_acc: 0.7275 - val_loss: 7.9698 - val_final_loss: 1.5867 - val_feature_loss: 0.0363 - val_final_acc: 0.5671\n",
      "\n",
      "Epoch 00059: val_final_acc improved from 0.56611 to 0.56707, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 60/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 5.6865 - final_loss: 1.1588 - feature_loss: -0.1075 - final_acc: 0.7296 - val_loss: 7.9883 - val_final_loss: 1.5901 - val_feature_loss: 0.0380 - val_final_acc: 0.5619\n",
      "\n",
      "Epoch 00060: val_final_acc did not improve from 0.56707\n",
      "Epoch 61/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 5.6108 - final_loss: 1.1438 - feature_loss: -0.1084 - final_acc: 0.7380 - val_loss: 8.0358 - val_final_loss: 1.5993 - val_feature_loss: 0.0392 - val_final_acc: 0.5549\n",
      "\n",
      "Epoch 00061: val_final_acc did not improve from 0.56707\n",
      "Epoch 62/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 5.4674 - final_loss: 1.1173 - feature_loss: -0.1190 - final_acc: 0.7488 - val_loss: 7.9514 - val_final_loss: 1.5820 - val_feature_loss: 0.0415 - val_final_acc: 0.5680\n",
      "\n",
      "Epoch 00062: val_final_acc improved from 0.56707 to 0.56804, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 63/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 5.4301 - final_loss: 1.1096 - feature_loss: -0.1178 - final_acc: 0.7446 - val_loss: 7.7912 - val_final_loss: 1.5522 - val_feature_loss: 0.0303 - val_final_acc: 0.5732\n",
      "\n",
      "Epoch 00063: val_final_acc improved from 0.56804 to 0.57317, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 64/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 5.2527 - final_loss: 1.0757 - feature_loss: -0.1258 - final_acc: 0.7494 - val_loss: 7.8199 - val_final_loss: 1.5566 - val_feature_loss: 0.0370 - val_final_acc: 0.5751\n",
      "\n",
      "Epoch 00064: val_final_acc improved from 0.57317 to 0.57510, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 65/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 5.0593 - final_loss: 1.0389 - feature_loss: -0.1354 - final_acc: 0.7626 - val_loss: 7.7868 - val_final_loss: 1.5508 - val_feature_loss: 0.0328 - val_final_acc: 0.5764\n",
      "\n",
      "Epoch 00065: val_final_acc improved from 0.57510 to 0.57638, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 66/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 5.1499 - final_loss: 1.0565 - feature_loss: -0.1324 - final_acc: 0.7537 - val_loss: 7.7786 - val_final_loss: 1.5490 - val_feature_loss: 0.0338 - val_final_acc: 0.5658\n",
      "\n",
      "Epoch 00066: val_final_acc did not improve from 0.57638\n",
      "Epoch 67/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 5.0168 - final_loss: 1.0308 - feature_loss: -0.1371 - final_acc: 0.7604 - val_loss: 8.0713 - val_final_loss: 1.6057 - val_feature_loss: 0.0427 - val_final_acc: 0.5481\n",
      "\n",
      "Epoch 00067: val_final_acc did not improve from 0.57638\n",
      "Epoch 68/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 4.9891 - final_loss: 1.0250 - feature_loss: -0.1361 - final_acc: 0.7624 - val_loss: 7.8806 - val_final_loss: 1.5685 - val_feature_loss: 0.0382 - val_final_acc: 0.5655\n",
      "\n",
      "Epoch 00068: val_final_acc did not improve from 0.57638\n",
      "Epoch 69/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 4.8162 - final_loss: 0.9924 - feature_loss: -0.1457 - final_acc: 0.7682 - val_loss: 7.8398 - val_final_loss: 1.5613 - val_feature_loss: 0.0335 - val_final_acc: 0.5684\n",
      "\n",
      "Epoch 00069: val_final_acc did not improve from 0.57638\n",
      "Epoch 70/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 4.8025 - final_loss: 0.9888 - feature_loss: -0.1416 - final_acc: 0.7695 - val_loss: 7.5940 - val_final_loss: 1.5129 - val_feature_loss: 0.0294 - val_final_acc: 0.5815\n",
      "\n",
      "Epoch 00070: val_final_acc improved from 0.57638 to 0.58151, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 71/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 4.5064 - final_loss: 0.9328 - feature_loss: -0.1576 - final_acc: 0.7852 - val_loss: 7.5868 - val_final_loss: 1.5107 - val_feature_loss: 0.0333 - val_final_acc: 0.5834\n",
      "\n",
      "Epoch 00071: val_final_acc improved from 0.58151 to 0.58344, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 72/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 4.5997 - final_loss: 0.9497 - feature_loss: -0.1489 - final_acc: 0.7808 - val_loss: 7.6097 - val_final_loss: 1.5153 - val_feature_loss: 0.0334 - val_final_acc: 0.5834\n",
      "\n",
      "Epoch 00072: val_final_acc did not improve from 0.58344\n",
      "Epoch 73/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 4.3042 - final_loss: 0.8946 - feature_loss: -0.1688 - final_acc: 0.8011 - val_loss: 7.8153 - val_final_loss: 1.5556 - val_feature_loss: 0.0374 - val_final_acc: 0.5716\n",
      "\n",
      "Epoch 00073: val_final_acc did not improve from 0.58344\n",
      "Epoch 74/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 4.2825 - final_loss: 0.8905 - feature_loss: -0.1698 - final_acc: 0.7996 - val_loss: 7.5493 - val_final_loss: 1.5051 - val_feature_loss: 0.0240 - val_final_acc: 0.5886\n",
      "\n",
      "Epoch 00074: val_final_acc improved from 0.58344 to 0.58858, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 75/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 4.1058 - final_loss: 0.8567 - feature_loss: -0.1778 - final_acc: 0.8093 - val_loss: 7.6738 - val_final_loss: 1.5277 - val_feature_loss: 0.0352 - val_final_acc: 0.5732\n",
      "\n",
      "Epoch 00075: val_final_acc did not improve from 0.58858\n",
      "Epoch 76/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 4.0772 - final_loss: 0.8509 - feature_loss: -0.1774 - final_acc: 0.8087 - val_loss: 7.4983 - val_final_loss: 1.4959 - val_feature_loss: 0.0189 - val_final_acc: 0.5889\n",
      "\n",
      "Epoch 00076: val_final_acc improved from 0.58858 to 0.58890, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 77/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 3.9754 - final_loss: 0.8315 - feature_loss: -0.1823 - final_acc: 0.8132 - val_loss: 7.5963 - val_final_loss: 1.5132 - val_feature_loss: 0.0302 - val_final_acc: 0.5863\n",
      "\n",
      "Epoch 00077: val_final_acc did not improve from 0.58890\n",
      "Epoch 78/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 3.8987 - final_loss: 0.8173 - feature_loss: -0.1876 - final_acc: 0.8230 - val_loss: 7.5816 - val_final_loss: 1.5100 - val_feature_loss: 0.0318 - val_final_acc: 0.5783\n",
      "\n",
      "Epoch 00078: val_final_acc did not improve from 0.58890\n",
      "Epoch 79/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 3.8594 - final_loss: 0.8096 - feature_loss: -0.1886 - final_acc: 0.8157 - val_loss: 7.5773 - val_final_loss: 1.5091 - val_feature_loss: 0.0319 - val_final_acc: 0.5860\n",
      "\n",
      "Epoch 00079: val_final_acc did not improve from 0.58890\n",
      "Epoch 80/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 3.9476 - final_loss: 0.8257 - feature_loss: -0.1811 - final_acc: 0.8075 - val_loss: 7.7224 - val_final_loss: 1.5371 - val_feature_loss: 0.0367 - val_final_acc: 0.5674\n",
      "\n",
      "Epoch 00080: val_final_acc did not improve from 0.58890\n",
      "Epoch 81/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 3.8745 - final_loss: 0.8113 - feature_loss: -0.1822 - final_acc: 0.8143 - val_loss: 7.7473 - val_final_loss: 1.5417 - val_feature_loss: 0.0388 - val_final_acc: 0.5696\n",
      "\n",
      "Epoch 00081: val_final_acc did not improve from 0.58890\n",
      "Epoch 82/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 3.7418 - final_loss: 0.7863 - feature_loss: -0.1896 - final_acc: 0.8217 - val_loss: 7.4572 - val_final_loss: 1.4868 - val_feature_loss: 0.0234 - val_final_acc: 0.5924\n",
      "\n",
      "Epoch 00082: val_final_acc improved from 0.58890 to 0.59243, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 83/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 3.6128 - final_loss: 0.7617 - feature_loss: -0.1959 - final_acc: 0.8243 - val_loss: 7.5897 - val_final_loss: 1.5116 - val_feature_loss: 0.0319 - val_final_acc: 0.5799\n",
      "\n",
      "Epoch 00083: val_final_acc did not improve from 0.59243\n",
      "Epoch 84/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 3.4152 - final_loss: 0.7254 - feature_loss: -0.2118 - final_acc: 0.8410 - val_loss: 7.5606 - val_final_loss: 1.5059 - val_feature_loss: 0.0309 - val_final_acc: 0.5921\n",
      "\n",
      "Epoch 00084: val_final_acc did not improve from 0.59243\n",
      "Epoch 85/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 3.3872 - final_loss: 0.7196 - feature_loss: -0.2106 - final_acc: 0.8374 - val_loss: 7.5835 - val_final_loss: 1.5096 - val_feature_loss: 0.0357 - val_final_acc: 0.5822\n",
      "\n",
      "Epoch 00085: val_final_acc did not improve from 0.59243\n",
      "Epoch 86/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 3.3708 - final_loss: 0.7159 - feature_loss: -0.2089 - final_acc: 0.8386 - val_loss: 7.5691 - val_final_loss: 1.5084 - val_feature_loss: 0.0270 - val_final_acc: 0.5902\n",
      "\n",
      "Epoch 00086: val_final_acc did not improve from 0.59243\n",
      "Epoch 87/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 3.3395 - final_loss: 0.7105 - feature_loss: -0.2131 - final_acc: 0.8399 - val_loss: 7.4963 - val_final_loss: 1.4942 - val_feature_loss: 0.0251 - val_final_acc: 0.5979\n",
      "\n",
      "Epoch 00087: val_final_acc improved from 0.59243 to 0.59788, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 88/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 3.2555 - final_loss: 0.6952 - feature_loss: -0.2204 - final_acc: 0.8443 - val_loss: 7.5581 - val_final_loss: 1.5058 - val_feature_loss: 0.0292 - val_final_acc: 0.5841\n",
      "\n",
      "Epoch 00088: val_final_acc did not improve from 0.59788\n",
      "Epoch 89/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 3.1688 - final_loss: 0.6774 - feature_loss: -0.2180 - final_acc: 0.8465 - val_loss: 7.8177 - val_final_loss: 1.5543 - val_feature_loss: 0.0462 - val_final_acc: 0.5767\n",
      "\n",
      "Epoch 00089: val_final_acc did not improve from 0.59788\n",
      "Epoch 90/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 3.2113 - final_loss: 0.6858 - feature_loss: -0.2176 - final_acc: 0.8427 - val_loss: 7.9684 - val_final_loss: 1.5834 - val_feature_loss: 0.0515 - val_final_acc: 0.5635\n",
      "\n",
      "Epoch 00090: val_final_acc did not improve from 0.59788\n",
      "Epoch 91/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 3.1615 - final_loss: 0.6756 - feature_loss: -0.2165 - final_acc: 0.8467 - val_loss: 7.6264 - val_final_loss: 1.5180 - val_feature_loss: 0.0363 - val_final_acc: 0.5812\n",
      "\n",
      "Epoch 00091: val_final_acc did not improve from 0.59788\n",
      "Epoch 92/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 3.0000 - final_loss: 0.6458 - feature_loss: -0.2291 - final_acc: 0.8529 - val_loss: 7.4982 - val_final_loss: 1.4940 - val_feature_loss: 0.0283 - val_final_acc: 0.5940\n",
      "\n",
      "Epoch 00092: val_final_acc did not improve from 0.59788\n",
      "Epoch 93/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 2.9000 - final_loss: 0.6267 - feature_loss: -0.2336 - final_acc: 0.8613 - val_loss: 7.5325 - val_final_loss: 1.5012 - val_feature_loss: 0.0264 - val_final_acc: 0.5931\n",
      "\n",
      "Epoch 00093: val_final_acc did not improve from 0.59788\n",
      "Epoch 94/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 2.8937 - final_loss: 0.6257 - feature_loss: -0.2350 - final_acc: 0.8600 - val_loss: 7.7152 - val_final_loss: 1.5361 - val_feature_loss: 0.0348 - val_final_acc: 0.5761\n",
      "\n",
      "Epoch 00094: val_final_acc did not improve from 0.59788\n",
      "Epoch 95/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 2.7750 - final_loss: 0.6031 - feature_loss: -0.2404 - final_acc: 0.8674 - val_loss: 7.7360 - val_final_loss: 1.5401 - val_feature_loss: 0.0354 - val_final_acc: 0.5773\n",
      "\n",
      "Epoch 00095: val_final_acc did not improve from 0.59788\n",
      "Epoch 96/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 2.7053 - final_loss: 0.5906 - feature_loss: -0.2477 - final_acc: 0.8734 - val_loss: 7.4784 - val_final_loss: 1.4911 - val_feature_loss: 0.0231 - val_final_acc: 0.5921\n",
      "\n",
      "Epoch 00096: val_final_acc did not improve from 0.59788\n",
      "Epoch 97/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 2.6529 - final_loss: 0.5803 - feature_loss: -0.2485 - final_acc: 0.8793 - val_loss: 7.6169 - val_final_loss: 1.5176 - val_feature_loss: 0.0290 - val_final_acc: 0.5809\n",
      "\n",
      "Epoch 00097: val_final_acc did not improve from 0.59788\n",
      "Epoch 98/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 2.5667 - final_loss: 0.5642 - feature_loss: -0.2543 - final_acc: 0.8773 - val_loss: 7.7613 - val_final_loss: 1.5446 - val_feature_loss: 0.0385 - val_final_acc: 0.5838\n",
      "\n",
      "Epoch 00098: val_final_acc did not improve from 0.59788\n",
      "Epoch 99/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 2.5121 - final_loss: 0.5539 - feature_loss: -0.2575 - final_acc: 0.8813 - val_loss: 7.7282 - val_final_loss: 1.5378 - val_feature_loss: 0.0392 - val_final_acc: 0.5834\n",
      "\n",
      "Epoch 00099: val_final_acc did not improve from 0.59788\n",
      "Epoch 100/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 2.5363 - final_loss: 0.5582 - feature_loss: -0.2547 - final_acc: 0.8781 - val_loss: 7.6357 - val_final_loss: 1.5213 - val_feature_loss: 0.0293 - val_final_acc: 0.5924\n",
      "\n",
      "Epoch 00100: val_final_acc did not improve from 0.59788\n",
      "Epoch 101/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 2.3995 - final_loss: 0.5328 - feature_loss: -0.2646 - final_acc: 0.8898 - val_loss: 7.7656 - val_final_loss: 1.5446 - val_feature_loss: 0.0424 - val_final_acc: 0.5838\n",
      "\n",
      "Epoch 00101: val_final_acc did not improve from 0.59788\n",
      "Epoch 102/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 2.3412 - final_loss: 0.5209 - feature_loss: -0.2632 - final_acc: 0.8874 - val_loss: 7.8099 - val_final_loss: 1.5546 - val_feature_loss: 0.0368 - val_final_acc: 0.5818\n",
      "\n",
      "Epoch 00102: val_final_acc did not improve from 0.59788\n",
      "Epoch 103/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 2.3623 - final_loss: 0.5259 - feature_loss: -0.2671 - final_acc: 0.8871 - val_loss: 7.6593 - val_final_loss: 1.5249 - val_feature_loss: 0.0348 - val_final_acc: 0.5921\n",
      "\n",
      "Epoch 00103: val_final_acc did not improve from 0.59788\n",
      "Epoch 104/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 2.2903 - final_loss: 0.5117 - feature_loss: -0.2680 - final_acc: 0.8894 - val_loss: 7.6818 - val_final_loss: 1.5306 - val_feature_loss: 0.0286 - val_final_acc: 0.5860\n",
      "\n",
      "Epoch 00104: val_final_acc did not improve from 0.59788\n",
      "Epoch 105/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 2.2235 - final_loss: 0.4998 - feature_loss: -0.2756 - final_acc: 0.8911 - val_loss: 7.8743 - val_final_loss: 1.5670 - val_feature_loss: 0.0393 - val_final_acc: 0.5838\n",
      "\n",
      "Epoch 00105: val_final_acc did not improve from 0.59788\n",
      "Epoch 106/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 2.1990 - final_loss: 0.4948 - feature_loss: -0.2748 - final_acc: 0.8938 - val_loss: 7.7132 - val_final_loss: 1.5361 - val_feature_loss: 0.0327 - val_final_acc: 0.5902\n",
      "\n",
      "Epoch 00106: val_final_acc did not improve from 0.59788\n",
      "Epoch 107/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 2.0756 - final_loss: 0.4715 - feature_loss: -0.2821 - final_acc: 0.9035 - val_loss: 7.5921 - val_final_loss: 1.5130 - val_feature_loss: 0.0271 - val_final_acc: 0.5969\n",
      "\n",
      "Epoch 00107: val_final_acc did not improve from 0.59788\n",
      "Epoch 108/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.9993 - final_loss: 0.4571 - feature_loss: -0.2864 - final_acc: 0.9054 - val_loss: 7.8851 - val_final_loss: 1.5688 - val_feature_loss: 0.0413 - val_final_acc: 0.5773\n",
      "\n",
      "Epoch 00108: val_final_acc did not improve from 0.59788\n",
      "Epoch 109/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 2.0693 - final_loss: 0.4698 - feature_loss: -0.2795 - final_acc: 0.8991 - val_loss: 7.8440 - val_final_loss: 1.5624 - val_feature_loss: 0.0319 - val_final_acc: 0.5895\n",
      "\n",
      "Epoch 00109: val_final_acc did not improve from 0.59788\n",
      "Epoch 110/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.9176 - final_loss: 0.4417 - feature_loss: -0.2908 - final_acc: 0.9114 - val_loss: 7.8574 - val_final_loss: 1.5633 - val_feature_loss: 0.0408 - val_final_acc: 0.5822\n",
      "\n",
      "Epoch 00110: val_final_acc did not improve from 0.59788\n",
      "Epoch 111/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.9692 - final_loss: 0.4509 - feature_loss: -0.2852 - final_acc: 0.9040 - val_loss: 7.8584 - val_final_loss: 1.5639 - val_feature_loss: 0.0388 - val_final_acc: 0.5883\n",
      "\n",
      "Epoch 00111: val_final_acc did not improve from 0.59788\n",
      "Epoch 112/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.9543 - final_loss: 0.4484 - feature_loss: -0.2877 - final_acc: 0.9050 - val_loss: 8.0494 - val_final_loss: 1.6009 - val_feature_loss: 0.0451 - val_final_acc: 0.5783\n",
      "\n",
      "Epoch 00112: val_final_acc did not improve from 0.59788\n",
      "Epoch 113/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.9345 - final_loss: 0.4441 - feature_loss: -0.2860 - final_acc: 0.9088 - val_loss: 7.8305 - val_final_loss: 1.5591 - val_feature_loss: 0.0348 - val_final_acc: 0.5822\n",
      "\n",
      "Epoch 00113: val_final_acc did not improve from 0.59788\n",
      "Epoch 114/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.8755 - final_loss: 0.4338 - feature_loss: -0.2937 - final_acc: 0.9088 - val_loss: 7.8777 - val_final_loss: 1.5696 - val_feature_loss: 0.0298 - val_final_acc: 0.5854\n",
      "\n",
      "Epoch 00114: val_final_acc did not improve from 0.59788\n",
      "Epoch 115/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.7956 - final_loss: 0.4189 - feature_loss: -0.2990 - final_acc: 0.9143 - val_loss: 7.7582 - val_final_loss: 1.5458 - val_feature_loss: 0.0292 - val_final_acc: 0.5947\n",
      "\n",
      "Epoch 00115: val_final_acc did not improve from 0.59788\n",
      "Epoch 116/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.7966 - final_loss: 0.4191 - feature_loss: -0.2987 - final_acc: 0.9140 - val_loss: 8.1667 - val_final_loss: 1.6222 - val_feature_loss: 0.0558 - val_final_acc: 0.5738\n",
      "\n",
      "Epoch 00116: val_final_acc did not improve from 0.59788\n",
      "Epoch 117/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.7903 - final_loss: 0.4171 - feature_loss: -0.2952 - final_acc: 0.9115 - val_loss: 7.8765 - val_final_loss: 1.5673 - val_feature_loss: 0.0399 - val_final_acc: 0.5905\n",
      "\n",
      "Epoch 00117: val_final_acc did not improve from 0.59788\n",
      "Epoch 118/2000\n",
      "25/25 [==============================] - 1s 50ms/step - loss: 1.7071 - final_loss: 0.4013 - feature_loss: -0.2995 - final_acc: 0.9165 - val_loss: 7.8299 - val_final_loss: 1.5603 - val_feature_loss: 0.0286 - val_final_acc: 0.5876\n",
      "\n",
      "Epoch 00118: val_final_acc did not improve from 0.59788\n",
      "Epoch 119/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.5996 - final_loss: 0.3824 - feature_loss: -0.3126 - final_acc: 0.9245 - val_loss: 7.9065 - val_final_loss: 1.5742 - val_feature_loss: 0.0356 - val_final_acc: 0.5886\n",
      "\n",
      "Epoch 00119: val_final_acc did not improve from 0.59788\n",
      "Epoch 120/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.5762 - final_loss: 0.3777 - feature_loss: -0.3126 - final_acc: 0.9242 - val_loss: 7.7614 - val_final_loss: 1.5468 - val_feature_loss: 0.0275 - val_final_acc: 0.5915\n",
      "\n",
      "Epoch 00120: val_final_acc did not improve from 0.59788\n",
      "Epoch 121/2000\n",
      "25/25 [==============================] - 1s 50ms/step - loss: 1.4959 - final_loss: 0.3624 - feature_loss: -0.3159 - final_acc: 0.9288 - val_loss: 7.9150 - val_final_loss: 1.5759 - val_feature_loss: 0.0357 - val_final_acc: 0.5873\n",
      "\n",
      "Epoch 00121: val_final_acc did not improve from 0.59788\n",
      "Epoch 122/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.4075 - final_loss: 0.3468 - feature_loss: -0.3267 - final_acc: 0.9336 - val_loss: 8.0424 - val_final_loss: 1.5999 - val_feature_loss: 0.0431 - val_final_acc: 0.5793\n",
      "\n",
      "Epoch 00122: val_final_acc did not improve from 0.59788\n",
      "Epoch 123/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 1.4879 - final_loss: 0.3615 - feature_loss: -0.3195 - final_acc: 0.9281 - val_loss: 7.9692 - val_final_loss: 1.5867 - val_feature_loss: 0.0359 - val_final_acc: 0.5883\n",
      "\n",
      "Epoch 00123: val_final_acc did not improve from 0.59788\n",
      "Epoch 124/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.4251 - final_loss: 0.3493 - feature_loss: -0.3212 - final_acc: 0.9344 - val_loss: 8.0302 - val_final_loss: 1.5981 - val_feature_loss: 0.0400 - val_final_acc: 0.5822\n",
      "\n",
      "Epoch 00124: val_final_acc did not improve from 0.59788\n",
      "Epoch 125/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.3958 - final_loss: 0.3431 - feature_loss: -0.3197 - final_acc: 0.9335 - val_loss: 7.8105 - val_final_loss: 1.5564 - val_feature_loss: 0.0284 - val_final_acc: 0.5950\n",
      "\n",
      "Epoch 00125: val_final_acc did not improve from 0.59788\n",
      "Epoch 126/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.2753 - final_loss: 0.3218 - feature_loss: -0.3336 - final_acc: 0.9418 - val_loss: 8.0286 - val_final_loss: 1.5985 - val_feature_loss: 0.0358 - val_final_acc: 0.5838\n",
      "\n",
      "Epoch 00126: val_final_acc did not improve from 0.59788\n",
      "Epoch 127/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.3065 - final_loss: 0.3280 - feature_loss: -0.3334 - final_acc: 0.9392 - val_loss: 7.8586 - val_final_loss: 1.5653 - val_feature_loss: 0.0318 - val_final_acc: 0.5985\n",
      "\n",
      "Epoch 00127: val_final_acc improved from 0.59788 to 0.59852, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 128/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.2093 - final_loss: 0.3091 - feature_loss: -0.3362 - final_acc: 0.9445 - val_loss: 7.9031 - val_final_loss: 1.5745 - val_feature_loss: 0.0306 - val_final_acc: 0.5870\n",
      "\n",
      "Epoch 00128: val_final_acc did not improve from 0.59852\n",
      "Epoch 129/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.2086 - final_loss: 0.3091 - feature_loss: -0.3367 - final_acc: 0.9406 - val_loss: 7.8938 - val_final_loss: 1.5741 - val_feature_loss: 0.0232 - val_final_acc: 0.5895\n",
      "\n",
      "Epoch 00129: val_final_acc did not improve from 0.59852\n",
      "Epoch 130/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.2176 - final_loss: 0.3109 - feature_loss: -0.3371 - final_acc: 0.9454 - val_loss: 8.0826 - val_final_loss: 1.6102 - val_feature_loss: 0.0315 - val_final_acc: 0.5924\n",
      "\n",
      "Epoch 00130: val_final_acc did not improve from 0.59852\n",
      "Epoch 131/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.2239 - final_loss: 0.3122 - feature_loss: -0.3370 - final_acc: 0.9416 - val_loss: 8.0398 - val_final_loss: 1.6006 - val_feature_loss: 0.0369 - val_final_acc: 0.5947\n",
      "\n",
      "Epoch 00131: val_final_acc did not improve from 0.59852\n",
      "Epoch 132/2000\n",
      "25/25 [==============================] - 1s 50ms/step - loss: 1.1615 - final_loss: 0.3002 - feature_loss: -0.3396 - final_acc: 0.9395 - val_loss: 8.0630 - val_final_loss: 1.6061 - val_feature_loss: 0.0325 - val_final_acc: 0.5911\n",
      "\n",
      "Epoch 00132: val_final_acc did not improve from 0.59852\n",
      "Epoch 133/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.1924 - final_loss: 0.3058 - feature_loss: -0.3364 - final_acc: 0.9413 - val_loss: 8.0539 - val_final_loss: 1.6030 - val_feature_loss: 0.0387 - val_final_acc: 0.5809\n",
      "\n",
      "Epoch 00133: val_final_acc did not improve from 0.59852\n",
      "Epoch 134/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.1021 - final_loss: 0.2882 - feature_loss: -0.3386 - final_acc: 0.9501 - val_loss: 7.9899 - val_final_loss: 1.5936 - val_feature_loss: 0.0221 - val_final_acc: 0.5956\n",
      "\n",
      "Epoch 00134: val_final_acc did not improve from 0.59852\n",
      "Epoch 135/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.0326 - final_loss: 0.2764 - feature_loss: -0.3496 - final_acc: 0.9519 - val_loss: 7.9589 - val_final_loss: 1.5871 - val_feature_loss: 0.0235 - val_final_acc: 0.5985\n",
      "\n",
      "Epoch 00135: val_final_acc did not improve from 0.59852\n",
      "Epoch 136/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.9985 - final_loss: 0.2709 - feature_loss: -0.3562 - final_acc: 0.9538 - val_loss: 8.0870 - val_final_loss: 1.6114 - val_feature_loss: 0.0300 - val_final_acc: 0.5918\n",
      "\n",
      "Epoch 00136: val_final_acc did not improve from 0.59852\n",
      "Epoch 137/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.9974 - final_loss: 0.2704 - feature_loss: -0.3545 - final_acc: 0.9522 - val_loss: 8.2763 - val_final_loss: 1.6480 - val_feature_loss: 0.0360 - val_final_acc: 0.5870\n",
      "\n",
      "Epoch 00137: val_final_acc did not improve from 0.59852\n",
      "Epoch 138/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.1874 - final_loss: 0.3051 - feature_loss: -0.3383 - final_acc: 0.9388 - val_loss: 8.0752 - val_final_loss: 1.6094 - val_feature_loss: 0.0283 - val_final_acc: 0.5908\n",
      "\n",
      "Epoch 00138: val_final_acc did not improve from 0.59852\n",
      "Epoch 139/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.0003 - final_loss: 0.2704 - feature_loss: -0.3515 - final_acc: 0.9482 - val_loss: 8.2351 - val_final_loss: 1.6399 - val_feature_loss: 0.0357 - val_final_acc: 0.5899\n",
      "\n",
      "Epoch 00139: val_final_acc did not improve from 0.59852\n",
      "Epoch 140/2000\n",
      "25/25 [==============================] - 1s 50ms/step - loss: 1.0157 - final_loss: 0.2735 - feature_loss: -0.3517 - final_acc: 0.9485 - val_loss: 8.3001 - val_final_loss: 1.6526 - val_feature_loss: 0.0371 - val_final_acc: 0.5918\n",
      "\n",
      "Epoch 00140: val_final_acc did not improve from 0.59852\n",
      "Epoch 141/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.9582 - final_loss: 0.2630 - feature_loss: -0.3570 - final_acc: 0.9528 - val_loss: 8.2746 - val_final_loss: 1.6472 - val_feature_loss: 0.0386 - val_final_acc: 0.5870\n",
      "\n",
      "Epoch 00141: val_final_acc did not improve from 0.59852\n",
      "Epoch 142/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 0.8887 - final_loss: 0.2499 - feature_loss: -0.3608 - final_acc: 0.9559 - val_loss: 8.3605 - val_final_loss: 1.6651 - val_feature_loss: 0.0351 - val_final_acc: 0.5902\n",
      "\n",
      "Epoch 00142: val_final_acc did not improve from 0.59852\n",
      "Epoch 143/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.9428 - final_loss: 0.2595 - feature_loss: -0.3548 - final_acc: 0.9530 - val_loss: 8.2345 - val_final_loss: 1.6404 - val_feature_loss: 0.0325 - val_final_acc: 0.5911\n",
      "\n",
      "Epoch 00143: val_final_acc did not improve from 0.59852\n",
      "Epoch 144/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.8747 - final_loss: 0.2467 - feature_loss: -0.3586 - final_acc: 0.9564 - val_loss: 8.2220 - val_final_loss: 1.6382 - val_feature_loss: 0.0312 - val_final_acc: 0.5931\n",
      "\n",
      "Epoch 00144: val_final_acc did not improve from 0.59852\n",
      "Epoch 145/2000\n",
      "25/25 [==============================] - 1s 50ms/step - loss: 0.8220 - final_loss: 0.2375 - feature_loss: -0.3656 - final_acc: 0.9612 - val_loss: 8.2520 - val_final_loss: 1.6439 - val_feature_loss: 0.0325 - val_final_acc: 0.5924\n",
      "\n",
      "Epoch 00145: val_final_acc did not improve from 0.59852\n",
      "Epoch 146/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.7165 - final_loss: 0.2188 - feature_loss: -0.3774 - final_acc: 0.9665 - val_loss: 8.3032 - val_final_loss: 1.6540 - val_feature_loss: 0.0329 - val_final_acc: 0.5985\n",
      "\n",
      "Epoch 00146: val_final_acc did not improve from 0.59852\n",
      "Epoch 147/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.7400 - final_loss: 0.2233 - feature_loss: -0.3766 - final_acc: 0.9626 - val_loss: 8.2760 - val_final_loss: 1.6485 - val_feature_loss: 0.0337 - val_final_acc: 0.5911\n",
      "\n",
      "Epoch 00147: val_final_acc did not improve from 0.59852\n",
      "Epoch 148/2000\n",
      "25/25 [==============================] - 1s 50ms/step - loss: 0.7889 - final_loss: 0.2316 - feature_loss: -0.3689 - final_acc: 0.9592 - val_loss: 8.3911 - val_final_loss: 1.6701 - val_feature_loss: 0.0408 - val_final_acc: 0.5825\n",
      "\n",
      "Epoch 00148: val_final_acc did not improve from 0.59852\n",
      "Epoch 149/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.7775 - final_loss: 0.2286 - feature_loss: -0.3656 - final_acc: 0.9599 - val_loss: 8.5646 - val_final_loss: 1.7041 - val_feature_loss: 0.0440 - val_final_acc: 0.5860\n",
      "\n",
      "Epoch 00149: val_final_acc did not improve from 0.59852\n",
      "Epoch 150/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.7002 - final_loss: 0.2155 - feature_loss: -0.3771 - final_acc: 0.9641 - val_loss: 8.3650 - val_final_loss: 1.6670 - val_feature_loss: 0.0303 - val_final_acc: 0.5883\n",
      "\n",
      "Epoch 00150: val_final_acc did not improve from 0.59852\n",
      "Epoch 151/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.7321 - final_loss: 0.2212 - feature_loss: -0.3740 - final_acc: 0.9593 - val_loss: 8.4458 - val_final_loss: 1.6822 - val_feature_loss: 0.0347 - val_final_acc: 0.5883\n",
      "\n",
      "Epoch 00151: val_final_acc did not improve from 0.59852\n",
      "Epoch 152/2000\n",
      "25/25 [==============================] - 1s 50ms/step - loss: 0.8279 - final_loss: 0.2378 - feature_loss: -0.3612 - final_acc: 0.9550 - val_loss: 8.4860 - val_final_loss: 1.6898 - val_feature_loss: 0.0369 - val_final_acc: 0.5841\n",
      "\n",
      "Epoch 00152: val_final_acc did not improve from 0.59852\n",
      "Epoch 153/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.8297 - final_loss: 0.2385 - feature_loss: -0.3630 - final_acc: 0.9510 - val_loss: 8.3826 - val_final_loss: 1.6697 - val_feature_loss: 0.0343 - val_final_acc: 0.5950\n",
      "\n",
      "Epoch 00153: val_final_acc did not improve from 0.59852\n",
      "Epoch 154/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.8045 - final_loss: 0.2341 - feature_loss: -0.3660 - final_acc: 0.9573 - val_loss: 8.4148 - val_final_loss: 1.6761 - val_feature_loss: 0.0345 - val_final_acc: 0.5825\n",
      "\n",
      "Epoch 00154: val_final_acc did not improve from 0.59852\n",
      "Epoch 155/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.7838 - final_loss: 0.2296 - feature_loss: -0.3641 - final_acc: 0.9572 - val_loss: 8.4639 - val_final_loss: 1.6858 - val_feature_loss: 0.0347 - val_final_acc: 0.5908\n",
      "\n",
      "Epoch 00155: val_final_acc did not improve from 0.59852\n",
      "Epoch 156/2000\n",
      "25/25 [==============================] - 1s 50ms/step - loss: 0.6750 - final_loss: 0.2107 - feature_loss: -0.3787 - final_acc: 0.9583 - val_loss: 8.3317 - val_final_loss: 1.6609 - val_feature_loss: 0.0272 - val_final_acc: 0.5944\n",
      "\n",
      "Epoch 00156: val_final_acc did not improve from 0.59852\n",
      "Epoch 157/2000\n",
      "25/25 [==============================] - 1s 50ms/step - loss: 0.6377 - final_loss: 0.2040 - feature_loss: -0.3822 - final_acc: 0.9634 - val_loss: 8.5261 - val_final_loss: 1.6995 - val_feature_loss: 0.0286 - val_final_acc: 0.5950\n",
      "\n",
      "Epoch 00157: val_final_acc did not improve from 0.59852\n",
      "Epoch 158/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.5654 - final_loss: 0.1912 - feature_loss: -0.3907 - final_acc: 0.9668 - val_loss: 8.5955 - val_final_loss: 1.7116 - val_feature_loss: 0.0373 - val_final_acc: 0.5854\n",
      "\n",
      "Epoch 00158: val_final_acc did not improve from 0.59852\n",
      "Epoch 159/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.5433 - final_loss: 0.1865 - feature_loss: -0.3892 - final_acc: 0.9683 - val_loss: 8.4798 - val_final_loss: 1.6895 - val_feature_loss: 0.0324 - val_final_acc: 0.5863\n",
      "\n",
      "Epoch 00159: val_final_acc did not improve from 0.59852\n",
      "Epoch 160/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.5881 - final_loss: 0.1950 - feature_loss: -0.3871 - final_acc: 0.9648 - val_loss: 8.6135 - val_final_loss: 1.7153 - val_feature_loss: 0.0371 - val_final_acc: 0.5886\n",
      "\n",
      "Epoch 00160: val_final_acc did not improve from 0.59852\n",
      "Epoch 161/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.5684 - final_loss: 0.1913 - feature_loss: -0.3878 - final_acc: 0.9665 - val_loss: 8.6090 - val_final_loss: 1.7144 - val_feature_loss: 0.0370 - val_final_acc: 0.5825\n",
      "\n",
      "Epoch 00161: val_final_acc did not improve from 0.59852\n",
      "Epoch 162/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.6037 - final_loss: 0.1963 - feature_loss: -0.3780 - final_acc: 0.9644 - val_loss: 8.5562 - val_final_loss: 1.7047 - val_feature_loss: 0.0329 - val_final_acc: 0.5902\n",
      "\n",
      "Epoch 00162: val_final_acc did not improve from 0.59852\n",
      "Epoch 163/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.5450 - final_loss: 0.1863 - feature_loss: -0.3865 - final_acc: 0.9680 - val_loss: 8.5003 - val_final_loss: 1.6933 - val_feature_loss: 0.0337 - val_final_acc: 0.5895\n",
      "\n",
      "Epoch 00163: val_final_acc did not improve from 0.59852\n",
      "Epoch 164/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.4890 - final_loss: 0.1759 - feature_loss: -0.3907 - final_acc: 0.9699 - val_loss: 8.8029 - val_final_loss: 1.7528 - val_feature_loss: 0.0388 - val_final_acc: 0.5815\n",
      "\n",
      "Epoch 00164: val_final_acc did not improve from 0.59852\n",
      "Epoch 165/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.5635 - final_loss: 0.1899 - feature_loss: -0.3862 - final_acc: 0.9666 - val_loss: 8.6770 - val_final_loss: 1.7275 - val_feature_loss: 0.0397 - val_final_acc: 0.5892\n",
      "\n",
      "Epoch 00165: val_final_acc did not improve from 0.59852\n",
      "Epoch 166/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.6312 - final_loss: 0.2020 - feature_loss: -0.3788 - final_acc: 0.9606 - val_loss: 9.0803 - val_final_loss: 1.8062 - val_feature_loss: 0.0494 - val_final_acc: 0.5777\n",
      "\n",
      "Epoch 00166: val_final_acc did not improve from 0.59852\n",
      "Epoch 167/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.7222 - final_loss: 0.2185 - feature_loss: -0.3701 - final_acc: 0.9538 - val_loss: 8.6338 - val_final_loss: 1.7198 - val_feature_loss: 0.0350 - val_final_acc: 0.5982\n",
      "\n",
      "Epoch 00167: val_final_acc did not improve from 0.59852\n",
      "validation accuracy 0.5985237483953787,0.4177344951307022\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_trained_model(X_train,y_train,n_timesteps,n_channels,window_size,filepath):\n",
    "    n_classes = len(np.unique(y_train))\n",
    "    model =  get_model(input_shape=(n_timesteps,n_channels),n_classes=n_classes)\n",
    "    checkpoint = callbacks.ModelCheckpoint(filepath, monitor='val_final_acc', verbose=1, save_best_only=True, mode='max',save_weights_only=False)\n",
    "    es = callbacks.EarlyStopping(monitor='val_final_acc', mode='max', verbose=0,patience=40)\n",
    "    callbacks_list = [es,checkpoint]\n",
    "    train_x,val_x,train_y,val_y = train_test_split(X_train,y_train,test_size=.2,stratify=y_train)\n",
    "    history = model.fit(train_x,[train_y,train_y],validation_data=(val_x,[val_y,val_y]), epochs=2000, batch_size=500,verbose=1,callbacks=callbacks_list,shuffle=True)\n",
    "    model.load_weights(filepath)\n",
    "    val_y_pred = model.predict(val_x)\n",
    "    if len(val_y_pred)<val_x.shape[0]:\n",
    "        val_y_pred = val_y_pred[0]\n",
    "    print('validation accuracy',accuracy_score(val_y,val_y_pred.argmax(axis=1)),end=',')\n",
    "    return model\n",
    "import tensorflow_addons as tfa\n",
    "def get_model(input_shape=(400,3),n_classes=1):\n",
    "    input_ = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv1D(128,2,activation='relu',kernel_initializer='normal',padding='same')(input_)\n",
    "    x = layers.MaxPooling1D(2)(x)\n",
    "    # x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv1D(128,2,activation='relu',kernel_initializer='normal',padding='same')(x)\n",
    "    # x = layers.MaxPooling1D(2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    # x = layers.Activation('tanh')(x)\n",
    "    x = layers.Dropout(.2)(x)\n",
    "    x = layers.GRU(128,return_sequences=False,activation='tanh')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(350,activation='relu')(x)\n",
    "    x = layers.Dense(n_classes,activation='relu',name='feature_before')(x)\n",
    "    y2 = layers.Lambda(lambda a:K.l2_normalize(a,axis=1),name='feature')(x)\n",
    "    y3 = layers.Dense(n_classes,activation='relu',name='final_before')(y2)\n",
    "    y1  =layers.Activation(activation='softmax',name='final')(y3)\n",
    "    model = models.Model(input_,[y1,y2])\n",
    "    model.compile(loss={'final':tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                        'feature':get_consistency_distinction_loss},\n",
    "                  loss_weights = {'final':5,'feature':1},\n",
    "                  optimizer='adam',\n",
    "                  metrics={'final':['acc']})\n",
    "    return model\n",
    "def get_X_y_dict(training_data,user_dict = None):\n",
    "    if user_dict is None:\n",
    "        user_dict = {a:i for i,a in enumerate(training_data['user'].unique())}\n",
    "    training_data['label'] = training_data['user'].apply(lambda a:user_dict[a])\n",
    "    X = np.concatenate(list(training_data['final_data']))\n",
    "    y = np.array(training_data['label'].values)\n",
    "    return X,y,user_dict\n",
    "activity_label = 'Walking'\n",
    "window_size = 20\n",
    "base_directory = './data/mORAL_dataset_for_python_upload_09072020/'\n",
    "training_data = pickle.load(open(os.path.join(base_directory,'processed_data',activity_label,'train.p'),'rb')).sort_values('timestamp').reset_index(drop=True)\n",
    "testing_data = pickle.load(open(os.path.join(base_directory,'processed_data',activity_label,'test.p'),'rb')).sort_values('timestamp').reset_index(drop=True)\n",
    "if not os.path.isdir(os.path.join(base_directory,'results',activity_label)):\n",
    "    os.makedirs(os.path.join(base_directory,'results',activity_label))\n",
    "result_directory = os.path.join(base_directory,'results',activity_label)\n",
    "model_directory = os.path.join(result_directory,'activity_{}_window_size_new_v4_{}.h5'.format(activity_label,window_size))\n",
    "X_train,y_train,user_dict = get_X_y_dict(training_data)\n",
    "X_test,y_test,user_dict =  get_X_y_dict(testing_data,user_dict)\n",
    "trained_model = get_trained_model(X_train,y_train,n_timesteps=X_train.shape[1],n_channels=X_train.shape[-1],window_size=window_size,filepath=model_directory)\n",
    "y_pred_test = trained_model.predict(X_test)\n",
    "testing_data['embedding'] = list(y_pred_test[0])\n",
    "testing_data['prediction'] = list(y_pred_test[0].argmax(axis=1))\n",
    "print(accuracy_score(testing_data['label'],testing_data['prediction']))\n",
    "pickle.dump(testing_data,open(os.path.join(result_directory,'activity_{}_window_size_new_v4_{}.p'.format(activity_label,window_size)),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4177344951307022"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(testing_data['label'],testing_data['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51b244ab9aca612e739a0539ae1af887c58db9e180d786deb0ab1761def69c1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
