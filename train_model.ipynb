{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azim/miniconda3/envs/test1/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:38: UserWarning: You are currently using a nightly version of TensorFlow (2.5.0-dev20210310). \n",
      "TensorFlow Addons offers no support for the nightly versions of TensorFlow. Some things might work, some other might not. \n",
      "If you encounter a bug, do not file an issue on GitHub.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow_addons.losses import metric_learning\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras import backend as K\n",
    "import pickle\n",
    "import os\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "gpu_id = 1\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "# Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[gpu_id], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "def _pairwise_distances(feature_A, feature_B=None, squared=False):\n",
    "    \"\"\"\n",
    "    Directly from https://www.tensorflow.org/api_docs/python/tf/contrib/losses/metric_learning/triplet_semihard_loss\n",
    "    Computes the pairwise distance matrix with numerical stability.\n",
    "    output[i, j] = || feature[i, :] - feature[j, :] ||_2\n",
    "    Args:\n",
    "      feature_A: 2-D Tensor of size [number of data A, feature dimension].\n",
    "      feature_B: 2-D Tensor of size [number of data B, feature dimension].\n",
    "      squared: Boolean, whether or not to square the pairwise distances.\n",
    "    Returns:\n",
    "      pairwise_distances: 2-D Tensor of size [number of data A, number of data B].\n",
    "    \"\"\"\n",
    "    if feature_B is None:\n",
    "        feature_B = feature_A\n",
    "\n",
    "    pairwise_distances_squared = tf.add(\n",
    "        tf.reduce_sum(tf.square(feature_A), axis=[1], keepdims=True),\n",
    "        tf.reduce_sum(tf.square(tf.transpose(feature_B)), axis=[0], keepdims=True),\n",
    "    ) - 2.0 * tf.linalg.matmul(feature_A, tf.transpose(feature_B))\n",
    "\n",
    "    # Deal with numerical inaccuracies. Set small negatives to zero.\n",
    "    pairwise_distances_squared = tf.maximum(pairwise_distances_squared, 0.0)\n",
    "    # Get the mask where the zero distances are at.\n",
    "    error_mask = tf.less_equal(pairwise_distances_squared, 0.0)\n",
    "\n",
    "    # Optionally take the sqrt.\n",
    "    if squared:\n",
    "        pairwise_distances = pairwise_distances_squared\n",
    "    else:\n",
    "        pairwise_distances = tf.sqrt(\n",
    "            pairwise_distances_squared + tf.cast(error_mask, tf.float32) * 1e-16\n",
    "        )\n",
    "\n",
    "    # Undo conditionally adding 1e-16.\n",
    "    pairwise_distances = tf.multiply(\n",
    "        pairwise_distances, tf.cast(tf.logical_not(error_mask), tf.float32)\n",
    "    )\n",
    "\n",
    "    if feature_B is None:\n",
    "        num_data = tf.shape(feature_A)[0]\n",
    "        # Explicitly set diagonals to zero.\n",
    "        mask_offdiagonals = tf.ones_like(pairwise_distances) - tf.linalg.diag(\n",
    "            tf.ones([num_data])\n",
    "        )\n",
    "        pairwise_distances = tf.multiply(pairwise_distances, mask_offdiagonals)\n",
    "\n",
    "    return pairwise_distances\n",
    "def get_consistency_distinction_loss(labels,embeddings):\n",
    "    epsilon = 1e-7\n",
    "    lshape = tf.shape(labels)\n",
    "    labels = tf.reshape(labels, [lshape[0], 1])\n",
    "    clusters_labels, _, num_embeddings_per_cluster = tf.unique_with_counts(\n",
    "        tf.reshape(labels, [lshape[0]])\n",
    "        )    \n",
    "    num_clusters = tf.size(clusters_labels)\n",
    "    adjacency = tf.equal(\n",
    "        labels, tf.transpose(clusters_labels)\n",
    "    )  \n",
    "    centroids = tf.linalg.matmul(\n",
    "        tf.cast(adjacency, dtype=tf.float32), embeddings, transpose_a=True\n",
    "    )\n",
    "    centroids = tf.divide(\n",
    "        centroids,\n",
    "        tf.expand_dims(tf.cast(num_embeddings_per_cluster, dtype=tf.float32), axis=1),\n",
    "    )\n",
    "    pairwise_distances_distinction_first = _pairwise_distances(\n",
    "        feature_A=embeddings, feature_B=centroids, squared=True\n",
    "    )\n",
    "    pairwise_distances_distinction_first = pairwise_distances_distinction_first/tf.reshape(tf.reduce_max(pairwise_distances_distinction_first,axis=1),[lshape[0],1])\n",
    "    adjacency_not = tf.logical_not(adjacency)\n",
    "    pairwise_distances_distinction = tf.where(tf.cast(adjacency,tf.float32)==1.0,tf.reduce_max(pairwise_distances_distinction_first),pairwise_distances_distinction_first)\n",
    "    minimum_distance_to_other_cluster = tf.reduce_min(pairwise_distances_distinction,axis=1)\n",
    "    distinction_loss = tf.reduce_mean(minimum_distance_to_other_cluster)\n",
    "    mean_intra_class_distance = tf.reduce_mean(tf.boolean_mask(pairwise_distances_distinction_first,adjacency))\n",
    "    mean_inter_class_distance = tf.reduce_mean(tf.boolean_mask(pairwise_distances_distinction_first,tf.logical_not(adjacency)))\n",
    "    alpha = mean_intra_class_distance/ (mean_inter_class_distance+epsilon)\n",
    "    \n",
    "    \n",
    "    ## If mean is used as aggregation\n",
    "    pairwise_distances_distinction_first = tf.multiply(pairwise_distances_distinction_first, tf.cast(adjacency,tf.float32))\n",
    "    mean_distance_same_class = tf.reduce_max(pairwise_distances_distinction_first,axis=1)\n",
    "    consistency_loss = tf.reduce_mean(mean_distance_same_class)\n",
    "    \n",
    "    \n",
    "    ## If percentile is used as aggregation\n",
    "    # pairwise_distances_distinction_first = tf.multiply(pairwise_distances_distinction_first, tf.cast(adjacency,tf.float32))\n",
    "    # mean_distance_same_class = tf.reduce_max(pairwise_distances_distinction_first,axis=1)\n",
    "    # loss = tf.constant(0,dtype=tf.float32)\n",
    "    # for label in clusters_labels:\n",
    "    #     percentile_95 = tfp.stats.percentile(tf.where(labels==label,mean_distance_same_class,tf.reduce_max(mean_distance_same_class)),95)\n",
    "    #     loss+=percentile_95\n",
    "    # consistency_loss = loss/tf.cast(tf.size(clusters_labels),tf.float32)\n",
    "    \n",
    "    return  (1+alpha)*consistency_loss - distinction_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = tf.convert_to_tensor(np.random.randn(10,100),dtype=tf.float32)\n",
    "# labels = tf.convert_to_tensor(np.random.randint(0,4,10),dtype=tf.float32)\n",
    "# mask_for_equal = tf.math.equal(labels,tf.transpose(labels))\n",
    "# pairwise_distances = _pairwise_distances(embeddings,squared=True)\n",
    "# pairwise_distances = pairwise_distances/tf.reshape(tf.reduce_max(pairwise_distances,axis=1),[lshape[0],1])    \n",
    "# pairwise_distance_for_consistency  = tf.multiply(pairwise_distances, tf.cast(mask_for_equal,tf.float32))\n",
    "# counts_same_class = tf.reduce_sum(tf.cast(mask_for_equal,tf.float32),axis=1)\n",
    "# total_distance_same_class = tf.reduce_sum(pairwise_distance_for_consistency,axis=1)\n",
    "# mean_distance_same_class = total_distance_same_class/(counts_same_class-1+epsilon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "25/25 [==============================] - 3s 64ms/step - loss: 15.4779 - final_loss: 3.0302 - feature_loss: 0.3267 - final_acc: 0.0623 - val_loss: 15.2773 - val_final_loss: 3.0016 - val_feature_loss: 0.2695 - val_final_acc: 0.1053\n",
      "\n",
      "Epoch 00001: val_final_acc improved from -inf to 0.10526, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 2/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 15.1356 - final_loss: 2.9771 - feature_loss: 0.2500 - final_acc: 0.1419 - val_loss: 15.2081 - val_final_loss: 2.9915 - val_feature_loss: 0.2508 - val_final_acc: 0.0992\n",
      "\n",
      "Epoch 00002: val_final_acc did not improve from 0.10526\n",
      "Epoch 3/2000\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 14.9394 - final_loss: 2.9455 - feature_loss: 0.2121 - final_acc: 0.1642 - val_loss: 15.3830 - val_final_loss: 3.0094 - val_feature_loss: 0.3362 - val_final_acc: 0.0927\n",
      "\n",
      "Epoch 00003: val_final_acc did not improve from 0.10526\n",
      "Epoch 4/2000\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 14.7886 - final_loss: 2.9203 - feature_loss: 0.1870 - final_acc: 0.1678 - val_loss: 15.0111 - val_final_loss: 2.9531 - val_feature_loss: 0.2455 - val_final_acc: 0.1139\n",
      "\n",
      "Epoch 00004: val_final_acc improved from 0.10526 to 0.11393, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 5/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 14.6002 - final_loss: 2.8871 - feature_loss: 0.1649 - final_acc: 0.1736 - val_loss: 14.8469 - val_final_loss: 2.9231 - val_feature_loss: 0.2316 - val_final_acc: 0.1046\n",
      "\n",
      "Epoch 00005: val_final_acc did not improve from 0.11393\n",
      "Epoch 6/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 14.5015 - final_loss: 2.8621 - feature_loss: 0.1909 - final_acc: 0.1734 - val_loss: 14.8639 - val_final_loss: 2.9155 - val_feature_loss: 0.2862 - val_final_acc: 0.1069\n",
      "\n",
      "Epoch 00006: val_final_acc did not improve from 0.11393\n",
      "Epoch 7/2000\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 14.1015 - final_loss: 2.7936 - feature_loss: 0.1337 - final_acc: 0.2085 - val_loss: 14.5799 - val_final_loss: 2.8737 - val_feature_loss: 0.2112 - val_final_acc: 0.1159\n",
      "\n",
      "Epoch 00007: val_final_acc improved from 0.11393 to 0.11585, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 8/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 13.8938 - final_loss: 2.7519 - feature_loss: 0.1343 - final_acc: 0.2397 - val_loss: 14.4645 - val_final_loss: 2.8500 - val_feature_loss: 0.2144 - val_final_acc: 0.1396\n",
      "\n",
      "Epoch 00008: val_final_acc improved from 0.11585 to 0.13960, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 9/2000\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 13.7169 - final_loss: 2.7170 - feature_loss: 0.1320 - final_acc: 0.2617 - val_loss: 14.4125 - val_final_loss: 2.8347 - val_feature_loss: 0.2389 - val_final_acc: 0.1643\n",
      "\n",
      "Epoch 00009: val_final_acc improved from 0.13960 to 0.16431, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 10/2000\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 13.4665 - final_loss: 2.6694 - feature_loss: 0.1196 - final_acc: 0.2865 - val_loss: 14.3353 - val_final_loss: 2.8228 - val_feature_loss: 0.2216 - val_final_acc: 0.1730\n",
      "\n",
      "Epoch 00010: val_final_acc improved from 0.16431 to 0.17298, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 11/2000\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 13.2582 - final_loss: 2.6289 - feature_loss: 0.1136 - final_acc: 0.3065 - val_loss: 14.2462 - val_final_loss: 2.8051 - val_feature_loss: 0.2207 - val_final_acc: 0.1784\n",
      "\n",
      "Epoch 00011: val_final_acc improved from 0.17298 to 0.17843, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 12/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 13.0593 - final_loss: 2.5908 - feature_loss: 0.1055 - final_acc: 0.3186 - val_loss: 14.0551 - val_final_loss: 2.7735 - val_feature_loss: 0.1877 - val_final_acc: 0.1755\n",
      "\n",
      "Epoch 00012: val_final_acc did not improve from 0.17843\n",
      "Epoch 13/2000\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 12.8052 - final_loss: 2.5423 - feature_loss: 0.0936 - final_acc: 0.3395 - val_loss: 13.8909 - val_final_loss: 2.7377 - val_feature_loss: 0.2024 - val_final_acc: 0.2041\n",
      "\n",
      "Epoch 00013: val_final_acc improved from 0.17843 to 0.20411, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 14/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 12.6379 - final_loss: 2.5104 - feature_loss: 0.0861 - final_acc: 0.3468 - val_loss: 13.5634 - val_final_loss: 2.6770 - val_feature_loss: 0.1784 - val_final_acc: 0.2189\n",
      "\n",
      "Epoch 00014: val_final_acc improved from 0.20411 to 0.21887, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 15/2000\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 12.3865 - final_loss: 2.4610 - feature_loss: 0.0813 - final_acc: 0.3707 - val_loss: 13.3626 - val_final_loss: 2.6412 - val_feature_loss: 0.1567 - val_final_acc: 0.2291\n",
      "\n",
      "Epoch 00015: val_final_acc improved from 0.21887 to 0.22914, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 16/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 12.1950 - final_loss: 2.4232 - feature_loss: 0.0791 - final_acc: 0.3836 - val_loss: 13.1842 - val_final_loss: 2.6041 - val_feature_loss: 0.1635 - val_final_acc: 0.2516\n",
      "\n",
      "Epoch 00016: val_final_acc improved from 0.22914 to 0.25160, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 17/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 11.9556 - final_loss: 2.3771 - feature_loss: 0.0701 - final_acc: 0.4007 - val_loss: 12.8510 - val_final_loss: 2.5418 - val_feature_loss: 0.1421 - val_final_acc: 0.2875\n",
      "\n",
      "Epoch 00017: val_final_acc improved from 0.25160 to 0.28755, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 18/2000\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 11.7726 - final_loss: 2.3415 - feature_loss: 0.0648 - final_acc: 0.4232 - val_loss: 12.7350 - val_final_loss: 2.5188 - val_feature_loss: 0.1408 - val_final_acc: 0.2888\n",
      "\n",
      "Epoch 00018: val_final_acc improved from 0.28755 to 0.28883, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 19/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 11.5356 - final_loss: 2.2957 - feature_loss: 0.0572 - final_acc: 0.4396 - val_loss: 12.1981 - val_final_loss: 2.4141 - val_feature_loss: 0.1276 - val_final_acc: 0.3556\n",
      "\n",
      "Epoch 00019: val_final_acc improved from 0.28883 to 0.35558, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 20/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 11.4160 - final_loss: 2.2711 - feature_loss: 0.0605 - final_acc: 0.4446 - val_loss: 11.8666 - val_final_loss: 2.3504 - val_feature_loss: 0.1144 - val_final_acc: 0.3720\n",
      "\n",
      "Epoch 00020: val_final_acc improved from 0.35558 to 0.37195, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 21/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 11.2685 - final_loss: 2.2428 - feature_loss: 0.0545 - final_acc: 0.4513 - val_loss: 11.6274 - val_final_loss: 2.3045 - val_feature_loss: 0.1051 - val_final_acc: 0.3922\n",
      "\n",
      "Epoch 00021: val_final_acc improved from 0.37195 to 0.39217, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 22/2000\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 11.0603 - final_loss: 2.2024 - feature_loss: 0.0482 - final_acc: 0.4617 - val_loss: 11.5282 - val_final_loss: 2.2839 - val_feature_loss: 0.1089 - val_final_acc: 0.3986\n",
      "\n",
      "Epoch 00022: val_final_acc improved from 0.39217 to 0.39859, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 23/2000\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 10.8129 - final_loss: 2.1552 - feature_loss: 0.0367 - final_acc: 0.4810 - val_loss: 11.2685 - val_final_loss: 2.2352 - val_feature_loss: 0.0925 - val_final_acc: 0.4201\n",
      "\n",
      "Epoch 00023: val_final_acc improved from 0.39859 to 0.42009, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 24/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 10.6423 - final_loss: 2.1207 - feature_loss: 0.0389 - final_acc: 0.4982 - val_loss: 11.2423 - val_final_loss: 2.2286 - val_feature_loss: 0.0991 - val_final_acc: 0.4175\n",
      "\n",
      "Epoch 00024: val_final_acc did not improve from 0.42009\n",
      "Epoch 25/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 10.5518 - final_loss: 2.1030 - feature_loss: 0.0368 - final_acc: 0.4986 - val_loss: 10.9015 - val_final_loss: 2.1652 - val_feature_loss: 0.0756 - val_final_acc: 0.4522\n",
      "\n",
      "Epoch 00025: val_final_acc improved from 0.42009 to 0.45218, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 26/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 10.3808 - final_loss: 2.0706 - feature_loss: 0.0278 - final_acc: 0.5089 - val_loss: 10.8941 - val_final_loss: 2.1609 - val_feature_loss: 0.0896 - val_final_acc: 0.4525\n",
      "\n",
      "Epoch 00026: val_final_acc improved from 0.45218 to 0.45250, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 27/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 10.1497 - final_loss: 2.0249 - feature_loss: 0.0252 - final_acc: 0.5288 - val_loss: 10.6459 - val_final_loss: 2.1148 - val_feature_loss: 0.0718 - val_final_acc: 0.4634\n",
      "\n",
      "Epoch 00027: val_final_acc improved from 0.45250 to 0.46341, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 28/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 9.9470 - final_loss: 1.9865 - feature_loss: 0.0143 - final_acc: 0.5348 - val_loss: 10.4252 - val_final_loss: 2.0718 - val_feature_loss: 0.0662 - val_final_acc: 0.4872\n",
      "\n",
      "Epoch 00028: val_final_acc improved from 0.46341 to 0.48716, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 29/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 9.7526 - final_loss: 1.9482 - feature_loss: 0.0117 - final_acc: 0.5433 - val_loss: 10.2752 - val_final_loss: 2.0426 - val_feature_loss: 0.0620 - val_final_acc: 0.4862\n",
      "\n",
      "Epoch 00029: val_final_acc did not improve from 0.48716\n",
      "Epoch 30/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 9.6609 - final_loss: 1.9313 - feature_loss: 0.0044 - final_acc: 0.5454 - val_loss: 10.3047 - val_final_loss: 2.0473 - val_feature_loss: 0.0680 - val_final_acc: 0.4791\n",
      "\n",
      "Epoch 00030: val_final_acc did not improve from 0.48716\n",
      "Epoch 31/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 9.4802 - final_loss: 1.8956 - feature_loss: 0.0021 - final_acc: 0.5596 - val_loss: 10.3006 - val_final_loss: 2.0439 - val_feature_loss: 0.0811 - val_final_acc: 0.4817\n",
      "\n",
      "Epoch 00031: val_final_acc did not improve from 0.48716\n",
      "Epoch 32/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 9.2591 - final_loss: 1.8530 - feature_loss: -0.0060 - final_acc: 0.5677 - val_loss: 10.1164 - val_final_loss: 2.0093 - val_feature_loss: 0.0700 - val_final_acc: 0.4836\n",
      "\n",
      "Epoch 00032: val_final_acc did not improve from 0.48716\n",
      "Epoch 33/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 9.2453 - final_loss: 1.8505 - feature_loss: -0.0072 - final_acc: 0.5668 - val_loss: 9.9574 - val_final_loss: 1.9794 - val_feature_loss: 0.0606 - val_final_acc: 0.4939\n",
      "\n",
      "Epoch 00033: val_final_acc improved from 0.48716 to 0.49390, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 34/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 8.9045 - final_loss: 1.7853 - feature_loss: -0.0220 - final_acc: 0.5903 - val_loss: 9.8031 - val_final_loss: 1.9492 - val_feature_loss: 0.0569 - val_final_acc: 0.4978\n",
      "\n",
      "Epoch 00034: val_final_acc improved from 0.49390 to 0.49775, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 35/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 8.8042 - final_loss: 1.7653 - feature_loss: -0.0222 - final_acc: 0.5870 - val_loss: 9.8768 - val_final_loss: 1.9607 - val_feature_loss: 0.0735 - val_final_acc: 0.4852\n",
      "\n",
      "Epoch 00035: val_final_acc did not improve from 0.49775\n",
      "Epoch 36/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 8.5790 - final_loss: 1.7218 - feature_loss: -0.0300 - final_acc: 0.5924 - val_loss: 9.4737 - val_final_loss: 1.8836 - val_feature_loss: 0.0558 - val_final_acc: 0.5116\n",
      "\n",
      "Epoch 00036: val_final_acc improved from 0.49775 to 0.51155, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 37/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 8.3663 - final_loss: 1.6801 - feature_loss: -0.0341 - final_acc: 0.6019 - val_loss: 9.3531 - val_final_loss: 1.8610 - val_feature_loss: 0.0481 - val_final_acc: 0.5157\n",
      "\n",
      "Epoch 00037: val_final_acc improved from 0.51155 to 0.51573, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 38/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 8.1617 - final_loss: 1.6407 - feature_loss: -0.0418 - final_acc: 0.6239 - val_loss: 9.2775 - val_final_loss: 1.8448 - val_feature_loss: 0.0533 - val_final_acc: 0.5234\n",
      "\n",
      "Epoch 00038: val_final_acc improved from 0.51573 to 0.52343, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 39/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 7.9748 - final_loss: 1.6044 - feature_loss: -0.0473 - final_acc: 0.6358 - val_loss: 9.1693 - val_final_loss: 1.8249 - val_feature_loss: 0.0450 - val_final_acc: 0.5247\n",
      "\n",
      "Epoch 00039: val_final_acc improved from 0.52343 to 0.52471, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 40/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 7.9799 - final_loss: 1.6055 - feature_loss: -0.0474 - final_acc: 0.6197 - val_loss: 9.0367 - val_final_loss: 1.7981 - val_feature_loss: 0.0463 - val_final_acc: 0.5334\n",
      "\n",
      "Epoch 00040: val_final_acc improved from 0.52471 to 0.53338, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 41/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 7.7343 - final_loss: 1.5575 - feature_loss: -0.0534 - final_acc: 0.6442 - val_loss: 9.0567 - val_final_loss: 1.8012 - val_feature_loss: 0.0506 - val_final_acc: 0.5324\n",
      "\n",
      "Epoch 00041: val_final_acc did not improve from 0.53338\n",
      "Epoch 42/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 7.7153 - final_loss: 1.5536 - feature_loss: -0.0527 - final_acc: 0.6397 - val_loss: 8.9178 - val_final_loss: 1.7732 - val_feature_loss: 0.0519 - val_final_acc: 0.5401\n",
      "\n",
      "Epoch 00042: val_final_acc improved from 0.53338 to 0.54012, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 43/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 7.4228 - final_loss: 1.4967 - feature_loss: -0.0608 - final_acc: 0.6630 - val_loss: 8.8647 - val_final_loss: 1.7644 - val_feature_loss: 0.0427 - val_final_acc: 0.5404\n",
      "\n",
      "Epoch 00043: val_final_acc improved from 0.54012 to 0.54044, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 44/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 7.1868 - final_loss: 1.4518 - feature_loss: -0.0723 - final_acc: 0.6743 - val_loss: 8.7763 - val_final_loss: 1.7462 - val_feature_loss: 0.0454 - val_final_acc: 0.5472\n",
      "\n",
      "Epoch 00044: val_final_acc improved from 0.54044 to 0.54718, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 45/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 7.1027 - final_loss: 1.4358 - feature_loss: -0.0760 - final_acc: 0.6813 - val_loss: 8.8664 - val_final_loss: 1.7614 - val_feature_loss: 0.0594 - val_final_acc: 0.5395\n",
      "\n",
      "Epoch 00045: val_final_acc did not improve from 0.54718\n",
      "Epoch 46/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 7.0082 - final_loss: 1.4167 - feature_loss: -0.0755 - final_acc: 0.6811 - val_loss: 8.6252 - val_final_loss: 1.7157 - val_feature_loss: 0.0466 - val_final_acc: 0.5571\n",
      "\n",
      "Epoch 00046: val_final_acc improved from 0.54718 to 0.55712, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 47/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 6.7927 - final_loss: 1.3762 - feature_loss: -0.0883 - final_acc: 0.6937 - val_loss: 8.6758 - val_final_loss: 1.7255 - val_feature_loss: 0.0482 - val_final_acc: 0.5392\n",
      "\n",
      "Epoch 00047: val_final_acc did not improve from 0.55712\n",
      "Epoch 48/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 6.7939 - final_loss: 1.3755 - feature_loss: -0.0834 - final_acc: 0.6846 - val_loss: 8.6660 - val_final_loss: 1.7235 - val_feature_loss: 0.0483 - val_final_acc: 0.5395\n",
      "\n",
      "Epoch 00048: val_final_acc did not improve from 0.55712\n",
      "Epoch 49/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 6.5664 - final_loss: 1.3325 - feature_loss: -0.0961 - final_acc: 0.7045 - val_loss: 8.3175 - val_final_loss: 1.6561 - val_feature_loss: 0.0370 - val_final_acc: 0.5610\n",
      "\n",
      "Epoch 00049: val_final_acc improved from 0.55712 to 0.56098, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 50/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 6.3298 - final_loss: 1.2866 - feature_loss: -0.1030 - final_acc: 0.7167 - val_loss: 8.3362 - val_final_loss: 1.6600 - val_feature_loss: 0.0364 - val_final_acc: 0.5568\n",
      "\n",
      "Epoch 00050: val_final_acc did not improve from 0.56098\n",
      "Epoch 51/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 6.1430 - final_loss: 1.2521 - feature_loss: -0.1175 - final_acc: 0.7322 - val_loss: 8.3872 - val_final_loss: 1.6688 - val_feature_loss: 0.0434 - val_final_acc: 0.5587\n",
      "\n",
      "Epoch 00051: val_final_acc did not improve from 0.56098\n",
      "Epoch 52/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 6.0000 - final_loss: 1.2243 - feature_loss: -0.1214 - final_acc: 0.7441 - val_loss: 8.3352 - val_final_loss: 1.6579 - val_feature_loss: 0.0457 - val_final_acc: 0.5668\n",
      "\n",
      "Epoch 00052: val_final_acc improved from 0.56098 to 0.56675, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 53/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 6.0286 - final_loss: 1.2290 - feature_loss: -0.1163 - final_acc: 0.7323 - val_loss: 8.2371 - val_final_loss: 1.6395 - val_feature_loss: 0.0397 - val_final_acc: 0.5626\n",
      "\n",
      "Epoch 00053: val_final_acc did not improve from 0.56675\n",
      "Epoch 54/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 5.7282 - final_loss: 1.1716 - feature_loss: -0.1297 - final_acc: 0.7536 - val_loss: 8.1993 - val_final_loss: 1.6323 - val_feature_loss: 0.0378 - val_final_acc: 0.5584\n",
      "\n",
      "Epoch 00054: val_final_acc did not improve from 0.56675\n",
      "Epoch 55/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 5.7265 - final_loss: 1.1714 - feature_loss: -0.1304 - final_acc: 0.7470 - val_loss: 8.1226 - val_final_loss: 1.6172 - val_feature_loss: 0.0367 - val_final_acc: 0.5613\n",
      "\n",
      "Epoch 00055: val_final_acc did not improve from 0.56675\n",
      "Epoch 56/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 5.4435 - final_loss: 1.1173 - feature_loss: -0.1432 - final_acc: 0.7641 - val_loss: 8.0505 - val_final_loss: 1.6028 - val_feature_loss: 0.0366 - val_final_acc: 0.5680\n",
      "\n",
      "Epoch 00056: val_final_acc improved from 0.56675 to 0.56804, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 57/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 5.3182 - final_loss: 1.0929 - feature_loss: -0.1462 - final_acc: 0.7674 - val_loss: 7.9919 - val_final_loss: 1.5912 - val_feature_loss: 0.0357 - val_final_acc: 0.5767\n",
      "\n",
      "Epoch 00057: val_final_acc improved from 0.56804 to 0.57670, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 58/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 5.2972 - final_loss: 1.0880 - feature_loss: -0.1429 - final_acc: 0.7731 - val_loss: 8.0460 - val_final_loss: 1.6020 - val_feature_loss: 0.0358 - val_final_acc: 0.5639\n",
      "\n",
      "Epoch 00058: val_final_acc did not improve from 0.57670\n",
      "Epoch 59/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 5.1192 - final_loss: 1.0552 - feature_loss: -0.1568 - final_acc: 0.7820 - val_loss: 8.0155 - val_final_loss: 1.5954 - val_feature_loss: 0.0384 - val_final_acc: 0.5732\n",
      "\n",
      "Epoch 00059: val_final_acc did not improve from 0.57670\n",
      "Epoch 60/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 5.0064 - final_loss: 1.0326 - feature_loss: -0.1568 - final_acc: 0.7914 - val_loss: 7.9539 - val_final_loss: 1.5841 - val_feature_loss: 0.0334 - val_final_acc: 0.5728\n",
      "\n",
      "Epoch 00060: val_final_acc did not improve from 0.57670\n",
      "Epoch 61/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 4.9077 - final_loss: 1.0144 - feature_loss: -0.1640 - final_acc: 0.7938 - val_loss: 7.9631 - val_final_loss: 1.5857 - val_feature_loss: 0.0348 - val_final_acc: 0.5735\n",
      "\n",
      "Epoch 00061: val_final_acc did not improve from 0.57670\n",
      "Epoch 62/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 4.7226 - final_loss: 0.9798 - feature_loss: -0.1764 - final_acc: 0.8019 - val_loss: 7.8651 - val_final_loss: 1.5672 - val_feature_loss: 0.0293 - val_final_acc: 0.5780\n",
      "\n",
      "Epoch 00062: val_final_acc improved from 0.57670 to 0.57798, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 63/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 4.7306 - final_loss: 0.9799 - feature_loss: -0.1690 - final_acc: 0.7943 - val_loss: 8.0245 - val_final_loss: 1.5959 - val_feature_loss: 0.0451 - val_final_acc: 0.5655\n",
      "\n",
      "Epoch 00063: val_final_acc did not improve from 0.57798\n",
      "Epoch 64/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 4.6825 - final_loss: 0.9702 - feature_loss: -0.1684 - final_acc: 0.7963 - val_loss: 7.8160 - val_final_loss: 1.5569 - val_feature_loss: 0.0317 - val_final_acc: 0.5844\n",
      "\n",
      "Epoch 00064: val_final_acc improved from 0.57798 to 0.58440, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 65/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 4.5096 - final_loss: 0.9379 - feature_loss: -0.1801 - final_acc: 0.8055 - val_loss: 7.9352 - val_final_loss: 1.5792 - val_feature_loss: 0.0394 - val_final_acc: 0.5757\n",
      "\n",
      "Epoch 00065: val_final_acc did not improve from 0.58440\n",
      "Epoch 66/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 4.2536 - final_loss: 0.8886 - feature_loss: -0.1896 - final_acc: 0.8236 - val_loss: 7.8675 - val_final_loss: 1.5667 - val_feature_loss: 0.0341 - val_final_acc: 0.5745\n",
      "\n",
      "Epoch 00066: val_final_acc did not improve from 0.58440\n",
      "Epoch 67/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 4.2487 - final_loss: 0.8872 - feature_loss: -0.1875 - final_acc: 0.8222 - val_loss: 7.7942 - val_final_loss: 1.5520 - val_feature_loss: 0.0340 - val_final_acc: 0.5806\n",
      "\n",
      "Epoch 00067: val_final_acc did not improve from 0.58440\n",
      "Epoch 68/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 4.1400 - final_loss: 0.8679 - feature_loss: -0.1997 - final_acc: 0.8280 - val_loss: 8.0477 - val_final_loss: 1.6003 - val_feature_loss: 0.0461 - val_final_acc: 0.5658\n",
      "\n",
      "Epoch 00068: val_final_acc did not improve from 0.58440\n",
      "Epoch 69/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 4.3711 - final_loss: 0.9096 - feature_loss: -0.1769 - final_acc: 0.8042 - val_loss: 8.0031 - val_final_loss: 1.5924 - val_feature_loss: 0.0410 - val_final_acc: 0.5693\n",
      "\n",
      "Epoch 00069: val_final_acc did not improve from 0.58440\n",
      "Epoch 70/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 3.9586 - final_loss: 0.8328 - feature_loss: -0.2054 - final_acc: 0.8346 - val_loss: 7.7616 - val_final_loss: 1.5460 - val_feature_loss: 0.0314 - val_final_acc: 0.5834\n",
      "\n",
      "Epoch 00070: val_final_acc did not improve from 0.58440\n",
      "Epoch 71/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 3.7762 - final_loss: 0.7978 - feature_loss: -0.2130 - final_acc: 0.8430 - val_loss: 7.8757 - val_final_loss: 1.5678 - val_feature_loss: 0.0364 - val_final_acc: 0.5735\n",
      "\n",
      "Epoch 00071: val_final_acc did not improve from 0.58440\n",
      "Epoch 72/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 3.7435 - final_loss: 0.7916 - feature_loss: -0.2143 - final_acc: 0.8422 - val_loss: 7.8010 - val_final_loss: 1.5534 - val_feature_loss: 0.0338 - val_final_acc: 0.5822\n",
      "\n",
      "Epoch 00072: val_final_acc did not improve from 0.58440\n",
      "Epoch 73/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 3.5743 - final_loss: 0.7590 - feature_loss: -0.2207 - final_acc: 0.8525 - val_loss: 7.7772 - val_final_loss: 1.5476 - val_feature_loss: 0.0389 - val_final_acc: 0.5700\n",
      "\n",
      "Epoch 00073: val_final_acc did not improve from 0.58440\n",
      "Epoch 74/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 3.5379 - final_loss: 0.7520 - feature_loss: -0.2220 - final_acc: 0.8507 - val_loss: 7.7762 - val_final_loss: 1.5485 - val_feature_loss: 0.0337 - val_final_acc: 0.5806\n",
      "\n",
      "Epoch 00074: val_final_acc did not improve from 0.58440\n",
      "Epoch 75/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 3.4841 - final_loss: 0.7416 - feature_loss: -0.2241 - final_acc: 0.8452 - val_loss: 7.7383 - val_final_loss: 1.5414 - val_feature_loss: 0.0315 - val_final_acc: 0.5825\n",
      "\n",
      "Epoch 00075: val_final_acc did not improve from 0.58440\n",
      "Epoch 76/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 3.3642 - final_loss: 0.7183 - feature_loss: -0.2273 - final_acc: 0.8569 - val_loss: 7.8528 - val_final_loss: 1.5619 - val_feature_loss: 0.0434 - val_final_acc: 0.5783\n",
      "\n",
      "Epoch 00076: val_final_acc did not improve from 0.58440\n",
      "Epoch 77/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 3.3168 - final_loss: 0.7089 - feature_loss: -0.2276 - final_acc: 0.8537 - val_loss: 7.8801 - val_final_loss: 1.5686 - val_feature_loss: 0.0373 - val_final_acc: 0.5645\n",
      "\n",
      "Epoch 00077: val_final_acc did not improve from 0.58440\n",
      "Epoch 78/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 3.3480 - final_loss: 0.7144 - feature_loss: -0.2240 - final_acc: 0.8518 - val_loss: 7.7294 - val_final_loss: 1.5385 - val_feature_loss: 0.0370 - val_final_acc: 0.5764\n",
      "\n",
      "Epoch 00078: val_final_acc did not improve from 0.58440\n",
      "Epoch 79/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 3.1928 - final_loss: 0.6841 - feature_loss: -0.2279 - final_acc: 0.8564 - val_loss: 7.8616 - val_final_loss: 1.5650 - val_feature_loss: 0.0368 - val_final_acc: 0.5725\n",
      "\n",
      "Epoch 00079: val_final_acc did not improve from 0.58440\n",
      "Epoch 80/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 3.0323 - final_loss: 0.6554 - feature_loss: -0.2447 - final_acc: 0.8679 - val_loss: 7.8033 - val_final_loss: 1.5547 - val_feature_loss: 0.0300 - val_final_acc: 0.5786\n",
      "\n",
      "Epoch 00080: val_final_acc did not improve from 0.58440\n",
      "Epoch 81/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 2.8427 - final_loss: 0.6200 - feature_loss: -0.2571 - final_acc: 0.8767 - val_loss: 7.6741 - val_final_loss: 1.5288 - val_feature_loss: 0.0302 - val_final_acc: 0.5850\n",
      "\n",
      "Epoch 00081: val_final_acc improved from 0.58440 to 0.58504, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 82/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 2.7064 - final_loss: 0.5941 - feature_loss: -0.2641 - final_acc: 0.8868 - val_loss: 7.7653 - val_final_loss: 1.5458 - val_feature_loss: 0.0361 - val_final_acc: 0.5773\n",
      "\n",
      "Epoch 00082: val_final_acc did not improve from 0.58504\n",
      "Epoch 83/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 2.7292 - final_loss: 0.5981 - feature_loss: -0.2616 - final_acc: 0.8814 - val_loss: 7.9083 - val_final_loss: 1.5732 - val_feature_loss: 0.0425 - val_final_acc: 0.5780\n",
      "\n",
      "Epoch 00083: val_final_acc did not improve from 0.58504\n",
      "Epoch 84/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 2.7136 - final_loss: 0.5950 - feature_loss: -0.2616 - final_acc: 0.8815 - val_loss: 7.8376 - val_final_loss: 1.5608 - val_feature_loss: 0.0334 - val_final_acc: 0.5767\n",
      "\n",
      "Epoch 00084: val_final_acc did not improve from 0.58504\n",
      "Epoch 85/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 2.6589 - final_loss: 0.5833 - feature_loss: -0.2576 - final_acc: 0.8813 - val_loss: 7.9789 - val_final_loss: 1.5872 - val_feature_loss: 0.0429 - val_final_acc: 0.5732\n",
      "\n",
      "Epoch 00085: val_final_acc did not improve from 0.58504\n",
      "Epoch 86/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 2.5553 - final_loss: 0.5645 - feature_loss: -0.2671 - final_acc: 0.8875 - val_loss: 7.7755 - val_final_loss: 1.5483 - val_feature_loss: 0.0339 - val_final_acc: 0.5806\n",
      "\n",
      "Epoch 00086: val_final_acc did not improve from 0.58504\n",
      "Epoch 87/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 2.4472 - final_loss: 0.5441 - feature_loss: -0.2731 - final_acc: 0.8935 - val_loss: 7.7753 - val_final_loss: 1.5494 - val_feature_loss: 0.0282 - val_final_acc: 0.5786\n",
      "\n",
      "Epoch 00087: val_final_acc did not improve from 0.58504\n",
      "Epoch 88/2000\n",
      "25/25 [==============================] - 1s 50ms/step - loss: 2.4734 - final_loss: 0.5486 - feature_loss: -0.2697 - final_acc: 0.8886 - val_loss: 7.7338 - val_final_loss: 1.5405 - val_feature_loss: 0.0315 - val_final_acc: 0.5802\n",
      "\n",
      "Epoch 00088: val_final_acc did not improve from 0.58504\n",
      "Epoch 89/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 2.4050 - final_loss: 0.5356 - feature_loss: -0.2731 - final_acc: 0.8903 - val_loss: 7.7782 - val_final_loss: 1.5493 - val_feature_loss: 0.0318 - val_final_acc: 0.5850\n",
      "\n",
      "Epoch 00089: val_final_acc did not improve from 0.58504\n",
      "Epoch 90/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 2.3308 - final_loss: 0.5226 - feature_loss: -0.2822 - final_acc: 0.8982 - val_loss: 7.7728 - val_final_loss: 1.5484 - val_feature_loss: 0.0310 - val_final_acc: 0.5850\n",
      "\n",
      "Epoch 00090: val_final_acc did not improve from 0.58504\n",
      "Epoch 91/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 2.3906 - final_loss: 0.5338 - feature_loss: -0.2782 - final_acc: 0.8898 - val_loss: 7.8485 - val_final_loss: 1.5625 - val_feature_loss: 0.0362 - val_final_acc: 0.5815\n",
      "\n",
      "Epoch 00091: val_final_acc did not improve from 0.58504\n",
      "Epoch 92/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 2.3326 - final_loss: 0.5221 - feature_loss: -0.2782 - final_acc: 0.8871 - val_loss: 7.7718 - val_final_loss: 1.5482 - val_feature_loss: 0.0310 - val_final_acc: 0.5822\n",
      "\n",
      "Epoch 00092: val_final_acc did not improve from 0.58504\n",
      "Epoch 93/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 2.1931 - final_loss: 0.4958 - feature_loss: -0.2861 - final_acc: 0.9010 - val_loss: 7.9552 - val_final_loss: 1.5819 - val_feature_loss: 0.0456 - val_final_acc: 0.5754\n",
      "\n",
      "Epoch 00093: val_final_acc did not improve from 0.58504\n",
      "Epoch 94/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 2.1304 - final_loss: 0.4842 - feature_loss: -0.2906 - final_acc: 0.9023 - val_loss: 7.7913 - val_final_loss: 1.5511 - val_feature_loss: 0.0355 - val_final_acc: 0.5796\n",
      "\n",
      "Epoch 00094: val_final_acc did not improve from 0.58504\n",
      "Epoch 95/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 2.0122 - final_loss: 0.4622 - feature_loss: -0.2987 - final_acc: 0.9092 - val_loss: 7.8511 - val_final_loss: 1.5629 - val_feature_loss: 0.0366 - val_final_acc: 0.5783\n",
      "\n",
      "Epoch 00095: val_final_acc did not improve from 0.58504\n",
      "Epoch 96/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.9320 - final_loss: 0.4477 - feature_loss: -0.3065 - final_acc: 0.9129 - val_loss: 7.7917 - val_final_loss: 1.5527 - val_feature_loss: 0.0282 - val_final_acc: 0.5828\n",
      "\n",
      "Epoch 00096: val_final_acc did not improve from 0.58504\n",
      "Epoch 97/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.8270 - final_loss: 0.4282 - feature_loss: -0.3139 - final_acc: 0.9182 - val_loss: 7.8331 - val_final_loss: 1.5605 - val_feature_loss: 0.0304 - val_final_acc: 0.5854\n",
      "\n",
      "Epoch 00097: val_final_acc improved from 0.58504 to 0.58537, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 98/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.8515 - final_loss: 0.4327 - feature_loss: -0.3117 - final_acc: 0.9183 - val_loss: 7.8892 - val_final_loss: 1.5720 - val_feature_loss: 0.0292 - val_final_acc: 0.5863\n",
      "\n",
      "Epoch 00098: val_final_acc improved from 0.58537 to 0.58633, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 99/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.8147 - final_loss: 0.4241 - feature_loss: -0.3055 - final_acc: 0.9189 - val_loss: 7.8308 - val_final_loss: 1.5602 - val_feature_loss: 0.0299 - val_final_acc: 0.5854\n",
      "\n",
      "Epoch 00099: val_final_acc did not improve from 0.58633\n",
      "Epoch 100/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.7828 - final_loss: 0.4199 - feature_loss: -0.3165 - final_acc: 0.9232 - val_loss: 7.9634 - val_final_loss: 1.5849 - val_feature_loss: 0.0389 - val_final_acc: 0.5796\n",
      "\n",
      "Epoch 00100: val_final_acc did not improve from 0.58633\n",
      "Epoch 101/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.7538 - final_loss: 0.4141 - feature_loss: -0.3165 - final_acc: 0.9185 - val_loss: 7.8994 - val_final_loss: 1.5734 - val_feature_loss: 0.0323 - val_final_acc: 0.5825\n",
      "\n",
      "Epoch 00101: val_final_acc did not improve from 0.58633\n",
      "Epoch 102/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.7245 - final_loss: 0.4074 - feature_loss: -0.3125 - final_acc: 0.9198 - val_loss: 7.9531 - val_final_loss: 1.5838 - val_feature_loss: 0.0341 - val_final_acc: 0.5789\n",
      "\n",
      "Epoch 00102: val_final_acc did not improve from 0.58633\n",
      "Epoch 103/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.5941 - final_loss: 0.3840 - feature_loss: -0.3259 - final_acc: 0.9266 - val_loss: 7.9739 - val_final_loss: 1.5875 - val_feature_loss: 0.0363 - val_final_acc: 0.5806\n",
      "\n",
      "Epoch 00103: val_final_acc did not improve from 0.58633\n",
      "Epoch 104/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.4392 - final_loss: 0.3562 - feature_loss: -0.3416 - final_acc: 0.9404 - val_loss: 8.0538 - val_final_loss: 1.6021 - val_feature_loss: 0.0433 - val_final_acc: 0.5831\n",
      "\n",
      "Epoch 00104: val_final_acc did not improve from 0.58633\n",
      "Epoch 105/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.5157 - final_loss: 0.3701 - feature_loss: -0.3348 - final_acc: 0.9324 - val_loss: 8.0036 - val_final_loss: 1.5929 - val_feature_loss: 0.0389 - val_final_acc: 0.5802\n",
      "\n",
      "Epoch 00105: val_final_acc did not improve from 0.58633\n",
      "Epoch 106/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.6992 - final_loss: 0.4034 - feature_loss: -0.3178 - final_acc: 0.9219 - val_loss: 8.2798 - val_final_loss: 1.6462 - val_feature_loss: 0.0490 - val_final_acc: 0.5773\n",
      "\n",
      "Epoch 00106: val_final_acc did not improve from 0.58633\n",
      "Epoch 107/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.5678 - final_loss: 0.3786 - feature_loss: -0.3252 - final_acc: 0.9270 - val_loss: 7.9854 - val_final_loss: 1.5905 - val_feature_loss: 0.0331 - val_final_acc: 0.5850\n",
      "\n",
      "Epoch 00107: val_final_acc did not improve from 0.58633\n",
      "Epoch 108/2000\n",
      "25/25 [==============================] - 1s 50ms/step - loss: 1.3228 - final_loss: 0.3345 - feature_loss: -0.3495 - final_acc: 0.9430 - val_loss: 8.0303 - val_final_loss: 1.5984 - val_feature_loss: 0.0380 - val_final_acc: 0.5796\n",
      "\n",
      "Epoch 00108: val_final_acc did not improve from 0.58633\n",
      "Epoch 109/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.3454 - final_loss: 0.3380 - feature_loss: -0.3444 - final_acc: 0.9405 - val_loss: 8.0323 - val_final_loss: 1.5998 - val_feature_loss: 0.0333 - val_final_acc: 0.5924\n",
      "\n",
      "Epoch 00109: val_final_acc improved from 0.58633 to 0.59243, saving model to ./data/mORAL_dataset_for_python_upload_09072020/results/Walking/activity_Walking_window_size_new_v4_20.h5\n",
      "Epoch 110/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.2619 - final_loss: 0.3229 - feature_loss: -0.3524 - final_acc: 0.9430 - val_loss: 8.0084 - val_final_loss: 1.5947 - val_feature_loss: 0.0349 - val_final_acc: 0.5892\n",
      "\n",
      "Epoch 00110: val_final_acc did not improve from 0.59243\n",
      "Epoch 111/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.2824 - final_loss: 0.3266 - feature_loss: -0.3504 - final_acc: 0.9428 - val_loss: 8.1086 - val_final_loss: 1.6147 - val_feature_loss: 0.0352 - val_final_acc: 0.5777\n",
      "\n",
      "Epoch 00111: val_final_acc did not improve from 0.59243\n",
      "Epoch 112/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.2357 - final_loss: 0.3172 - feature_loss: -0.3502 - final_acc: 0.9454 - val_loss: 8.0071 - val_final_loss: 1.5956 - val_feature_loss: 0.0292 - val_final_acc: 0.5886\n",
      "\n",
      "Epoch 00112: val_final_acc did not improve from 0.59243\n",
      "Epoch 113/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.2083 - final_loss: 0.3123 - feature_loss: -0.3533 - final_acc: 0.9456 - val_loss: 8.0357 - val_final_loss: 1.6007 - val_feature_loss: 0.0321 - val_final_acc: 0.5879\n",
      "\n",
      "Epoch 00113: val_final_acc did not improve from 0.59243\n",
      "Epoch 114/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.1484 - final_loss: 0.3021 - feature_loss: -0.3620 - final_acc: 0.9485 - val_loss: 8.0251 - val_final_loss: 1.5990 - val_feature_loss: 0.0300 - val_final_acc: 0.5924\n",
      "\n",
      "Epoch 00114: val_final_acc did not improve from 0.59243\n",
      "Epoch 115/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.1252 - final_loss: 0.2973 - feature_loss: -0.3614 - final_acc: 0.9452 - val_loss: 8.0908 - val_final_loss: 1.6119 - val_feature_loss: 0.0315 - val_final_acc: 0.5886\n",
      "\n",
      "Epoch 00115: val_final_acc did not improve from 0.59243\n",
      "Epoch 116/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.1143 - final_loss: 0.2959 - feature_loss: -0.3650 - final_acc: 0.9510 - val_loss: 8.1174 - val_final_loss: 1.6174 - val_feature_loss: 0.0303 - val_final_acc: 0.5879\n",
      "\n",
      "Epoch 00116: val_final_acc did not improve from 0.59243\n",
      "Epoch 117/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.0179 - final_loss: 0.2778 - feature_loss: -0.3713 - final_acc: 0.9558 - val_loss: 8.2043 - val_final_loss: 1.6342 - val_feature_loss: 0.0336 - val_final_acc: 0.5876\n",
      "\n",
      "Epoch 00117: val_final_acc did not improve from 0.59243\n",
      "Epoch 118/2000\n",
      "25/25 [==============================] - 1s 50ms/step - loss: 0.9410 - final_loss: 0.2641 - feature_loss: -0.3795 - final_acc: 0.9594 - val_loss: 8.1824 - val_final_loss: 1.6303 - val_feature_loss: 0.0311 - val_final_acc: 0.5873\n",
      "\n",
      "Epoch 00118: val_final_acc did not improve from 0.59243\n",
      "Epoch 119/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.9344 - final_loss: 0.2623 - feature_loss: -0.3770 - final_acc: 0.9582 - val_loss: 8.1170 - val_final_loss: 1.6170 - val_feature_loss: 0.0319 - val_final_acc: 0.5828\n",
      "\n",
      "Epoch 00119: val_final_acc did not improve from 0.59243\n",
      "Epoch 120/2000\n",
      "25/25 [==============================] - 1s 50ms/step - loss: 0.9999 - final_loss: 0.2740 - feature_loss: -0.3699 - final_acc: 0.9524 - val_loss: 8.1020 - val_final_loss: 1.6148 - val_feature_loss: 0.0281 - val_final_acc: 0.5905\n",
      "\n",
      "Epoch 00120: val_final_acc did not improve from 0.59243\n",
      "Epoch 121/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.9556 - final_loss: 0.2656 - feature_loss: -0.3723 - final_acc: 0.9583 - val_loss: 8.3634 - val_final_loss: 1.6654 - val_feature_loss: 0.0365 - val_final_acc: 0.5770\n",
      "\n",
      "Epoch 00121: val_final_acc did not improve from 0.59243\n",
      "Epoch 122/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.8821 - final_loss: 0.2527 - feature_loss: -0.3813 - final_acc: 0.9575 - val_loss: 8.3663 - val_final_loss: 1.6650 - val_feature_loss: 0.0413 - val_final_acc: 0.5796\n",
      "\n",
      "Epoch 00122: val_final_acc did not improve from 0.59243\n",
      "Epoch 123/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.7915 - final_loss: 0.2360 - feature_loss: -0.3885 - final_acc: 0.9623 - val_loss: 8.2457 - val_final_loss: 1.6428 - val_feature_loss: 0.0315 - val_final_acc: 0.5818\n",
      "\n",
      "Epoch 00123: val_final_acc did not improve from 0.59243\n",
      "Epoch 124/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.8469 - final_loss: 0.2466 - feature_loss: -0.3863 - final_acc: 0.9613 - val_loss: 8.2673 - val_final_loss: 1.6465 - val_feature_loss: 0.0346 - val_final_acc: 0.5818\n",
      "\n",
      "Epoch 00124: val_final_acc did not improve from 0.59243\n",
      "Epoch 125/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.9316 - final_loss: 0.2616 - feature_loss: -0.3762 - final_acc: 0.9552 - val_loss: 8.2988 - val_final_loss: 1.6530 - val_feature_loss: 0.0337 - val_final_acc: 0.5860\n",
      "\n",
      "Epoch 00125: val_final_acc did not improve from 0.59243\n",
      "Epoch 126/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.7964 - final_loss: 0.2363 - feature_loss: -0.3852 - final_acc: 0.9644 - val_loss: 8.3366 - val_final_loss: 1.6590 - val_feature_loss: 0.0414 - val_final_acc: 0.5789\n",
      "\n",
      "Epoch 00126: val_final_acc did not improve from 0.59243\n",
      "Epoch 127/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.6847 - final_loss: 0.2161 - feature_loss: -0.3960 - final_acc: 0.9668 - val_loss: 8.3259 - val_final_loss: 1.6580 - val_feature_loss: 0.0358 - val_final_acc: 0.5924\n",
      "\n",
      "Epoch 00127: val_final_acc did not improve from 0.59243\n",
      "Epoch 128/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.6861 - final_loss: 0.2165 - feature_loss: -0.3965 - final_acc: 0.9691 - val_loss: 8.3670 - val_final_loss: 1.6658 - val_feature_loss: 0.0381 - val_final_acc: 0.5863\n",
      "\n",
      "Epoch 00128: val_final_acc did not improve from 0.59243\n",
      "Epoch 129/2000\n",
      "25/25 [==============================] - 1s 50ms/step - loss: 0.7484 - final_loss: 0.2277 - feature_loss: -0.3902 - final_acc: 0.9635 - val_loss: 8.3259 - val_final_loss: 1.6587 - val_feature_loss: 0.0326 - val_final_acc: 0.5863\n",
      "\n",
      "Epoch 00129: val_final_acc did not improve from 0.59243\n",
      "Epoch 130/2000\n",
      "25/25 [==============================] - 1s 50ms/step - loss: 0.6120 - final_loss: 0.2033 - feature_loss: -0.4046 - final_acc: 0.9724 - val_loss: 8.5299 - val_final_loss: 1.6976 - val_feature_loss: 0.0420 - val_final_acc: 0.5789\n",
      "\n",
      "Epoch 00130: val_final_acc did not improve from 0.59243\n",
      "Epoch 131/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.6712 - final_loss: 0.2134 - feature_loss: -0.3959 - final_acc: 0.9659 - val_loss: 8.3218 - val_final_loss: 1.6582 - val_feature_loss: 0.0310 - val_final_acc: 0.5921\n",
      "\n",
      "Epoch 00131: val_final_acc did not improve from 0.59243\n",
      "Epoch 132/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.5560 - final_loss: 0.1931 - feature_loss: -0.4094 - final_acc: 0.9739 - val_loss: 8.4258 - val_final_loss: 1.6793 - val_feature_loss: 0.0294 - val_final_acc: 0.5857\n",
      "\n",
      "Epoch 00132: val_final_acc did not improve from 0.59243\n",
      "Epoch 133/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.6059 - final_loss: 0.2023 - feature_loss: -0.4058 - final_acc: 0.9689 - val_loss: 8.2738 - val_final_loss: 1.6489 - val_feature_loss: 0.0294 - val_final_acc: 0.5870\n",
      "\n",
      "Epoch 00133: val_final_acc did not improve from 0.59243\n",
      "Epoch 134/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.5737 - final_loss: 0.1958 - feature_loss: -0.4055 - final_acc: 0.9718 - val_loss: 8.3259 - val_final_loss: 1.6596 - val_feature_loss: 0.0277 - val_final_acc: 0.5908\n",
      "\n",
      "Epoch 00134: val_final_acc did not improve from 0.59243\n",
      "Epoch 135/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.5317 - final_loss: 0.1884 - feature_loss: -0.4103 - final_acc: 0.9723 - val_loss: 8.4861 - val_final_loss: 1.6902 - val_feature_loss: 0.0351 - val_final_acc: 0.5818\n",
      "\n",
      "Epoch 00135: val_final_acc did not improve from 0.59243\n",
      "Epoch 136/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.6178 - final_loss: 0.2039 - feature_loss: -0.4017 - final_acc: 0.9689 - val_loss: 8.5080 - val_final_loss: 1.6943 - val_feature_loss: 0.0363 - val_final_acc: 0.5870\n",
      "\n",
      "Epoch 00136: val_final_acc did not improve from 0.59243\n",
      "Epoch 137/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.5860 - final_loss: 0.1978 - feature_loss: -0.4031 - final_acc: 0.9695 - val_loss: 8.5714 - val_final_loss: 1.7067 - val_feature_loss: 0.0378 - val_final_acc: 0.5860\n",
      "\n",
      "Epoch 00137: val_final_acc did not improve from 0.59243\n",
      "Epoch 138/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.5642 - final_loss: 0.1937 - feature_loss: -0.4041 - final_acc: 0.9701 - val_loss: 8.5436 - val_final_loss: 1.7014 - val_feature_loss: 0.0368 - val_final_acc: 0.5879\n",
      "\n",
      "Epoch 00138: val_final_acc did not improve from 0.59243\n",
      "Epoch 139/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.5380 - final_loss: 0.1890 - feature_loss: -0.4068 - final_acc: 0.9699 - val_loss: 8.4261 - val_final_loss: 1.6796 - val_feature_loss: 0.0280 - val_final_acc: 0.5908\n",
      "\n",
      "Epoch 00139: val_final_acc did not improve from 0.59243\n",
      "Epoch 140/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.5014 - final_loss: 0.1828 - feature_loss: -0.4128 - final_acc: 0.9729 - val_loss: 8.4051 - val_final_loss: 1.6749 - val_feature_loss: 0.0304 - val_final_acc: 0.5883\n",
      "\n",
      "Epoch 00140: val_final_acc did not improve from 0.59243\n",
      "Epoch 141/2000\n",
      "25/25 [==============================] - 1s 50ms/step - loss: 0.4381 - final_loss: 0.1707 - feature_loss: -0.4156 - final_acc: 0.9775 - val_loss: 8.6574 - val_final_loss: 1.7240 - val_feature_loss: 0.0374 - val_final_acc: 0.5847\n",
      "\n",
      "Epoch 00141: val_final_acc did not improve from 0.59243\n",
      "Epoch 142/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.5426 - final_loss: 0.1900 - feature_loss: -0.4074 - final_acc: 0.9706 - val_loss: 8.4527 - val_final_loss: 1.6847 - val_feature_loss: 0.0290 - val_final_acc: 0.5863\n",
      "\n",
      "Epoch 00142: val_final_acc did not improve from 0.59243\n",
      "Epoch 143/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.4584 - final_loss: 0.1747 - feature_loss: -0.4150 - final_acc: 0.9751 - val_loss: 8.6532 - val_final_loss: 1.7238 - val_feature_loss: 0.0339 - val_final_acc: 0.5870\n",
      "\n",
      "Epoch 00143: val_final_acc did not improve from 0.59243\n",
      "Epoch 144/2000\n",
      "25/25 [==============================] - 1s 50ms/step - loss: 0.4199 - final_loss: 0.1680 - feature_loss: -0.4200 - final_acc: 0.9744 - val_loss: 8.6410 - val_final_loss: 1.7211 - val_feature_loss: 0.0356 - val_final_acc: 0.5822\n",
      "\n",
      "Epoch 00144: val_final_acc did not improve from 0.59243\n",
      "Epoch 145/2000\n",
      "25/25 [==============================] - 1s 50ms/step - loss: 0.3874 - final_loss: 0.1616 - feature_loss: -0.4205 - final_acc: 0.9775 - val_loss: 8.9007 - val_final_loss: 1.7718 - val_feature_loss: 0.0419 - val_final_acc: 0.5754\n",
      "\n",
      "Epoch 00145: val_final_acc did not improve from 0.59243\n",
      "Epoch 146/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.4248 - final_loss: 0.1700 - feature_loss: -0.4251 - final_acc: 0.9733 - val_loss: 8.8128 - val_final_loss: 1.7543 - val_feature_loss: 0.0414 - val_final_acc: 0.5799\n",
      "\n",
      "Epoch 00146: val_final_acc did not improve from 0.59243\n",
      "Epoch 147/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.3641 - final_loss: 0.1572 - feature_loss: -0.4218 - final_acc: 0.9770 - val_loss: 8.7502 - val_final_loss: 1.7420 - val_feature_loss: 0.0402 - val_final_acc: 0.5834\n",
      "\n",
      "Epoch 00147: val_final_acc did not improve from 0.59243\n",
      "Epoch 148/2000\n",
      "25/25 [==============================] - 1s 50ms/step - loss: 0.2850 - final_loss: 0.1435 - feature_loss: -0.4325 - final_acc: 0.9805 - val_loss: 8.6790 - val_final_loss: 1.7299 - val_feature_loss: 0.0293 - val_final_acc: 0.5902\n",
      "\n",
      "Epoch 00148: val_final_acc did not improve from 0.59243\n",
      "Epoch 149/2000\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.2842 - final_loss: 0.1430 - feature_loss: -0.4309 - final_acc: 0.9825 - val_loss: 8.6774 - val_final_loss: 1.7287 - val_feature_loss: 0.0338 - val_final_acc: 0.5895\n",
      "\n",
      "Epoch 00149: val_final_acc did not improve from 0.59243\n",
      "validation accuracy 0.5924261874197689,0.4097898513582778\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_trained_model(X_train,y_train,n_timesteps,n_channels,window_size,filepath):\n",
    "    n_classes = len(np.unique(y_train))\n",
    "    model =  get_model(input_shape=(n_timesteps,n_channels),n_classes=n_classes)\n",
    "    checkpoint = callbacks.ModelCheckpoint(filepath, monitor='val_final_acc', verbose=1, save_best_only=True, mode='max',save_weights_only=False)\n",
    "    es = callbacks.EarlyStopping(monitor='val_final_acc', mode='max', verbose=0,patience=40)\n",
    "    callbacks_list = [es,checkpoint]\n",
    "    train_x,val_x,train_y,val_y = train_test_split(X_train,y_train,test_size=.2,stratify=y_train)\n",
    "    history = model.fit(train_x,[train_y,train_y],validation_data=(val_x,[val_y,val_y]), epochs=2000, batch_size=500,verbose=1,callbacks=callbacks_list,shuffle=True)\n",
    "    model.load_weights(filepath)\n",
    "    val_y_pred = model.predict(val_x)\n",
    "    if len(val_y_pred)<val_x.shape[0]:\n",
    "        val_y_pred = val_y_pred[0]\n",
    "    print('validation accuracy',accuracy_score(val_y,val_y_pred.argmax(axis=1)),end=',')\n",
    "    return model\n",
    "import tensorflow_addons as tfa\n",
    "def get_model(input_shape=(400,3),n_classes=1):\n",
    "    input_ = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv1D(128,2,activation='relu',kernel_initializer='normal',padding='same')(input_)\n",
    "    x = layers.MaxPooling1D(2)(x)\n",
    "    # x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv1D(128,2,activation='relu',kernel_initializer='normal',padding='same')(x)\n",
    "    # x = layers.MaxPooling1D(2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    # x = layers.Activation('tanh')(x)\n",
    "    x = layers.Dropout(.2)(x)\n",
    "    x = layers.GRU(128,return_sequences=False,activation='tanh')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(350,activation='relu')(x)\n",
    "    x = layers.Dense(n_classes,activation='relu',name='feature_before')(x)\n",
    "    y2 = layers.Lambda(lambda a:K.l2_normalize(a,axis=1),name='feature')(x)\n",
    "    y3 = layers.Dense(n_classes,activation='relu',name='final_before')(y2)\n",
    "    y1  =layers.Activation(activation='softmax',name='final')(y3)\n",
    "    model = models.Model(input_,[y1,y2])\n",
    "    model.compile(loss={'final':tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                        'feature':get_consistency_distinction_loss},\n",
    "                  loss_weights = {'final':5,'feature':1},\n",
    "                  optimizer='adam',\n",
    "                  metrics={'final':['acc']})\n",
    "    return model\n",
    "def get_X_y_dict(training_data,user_dict = None):\n",
    "    if user_dict is None:\n",
    "        user_dict = {a:i for i,a in enumerate(training_data['user'].unique())}\n",
    "    training_data['label'] = training_data['user'].apply(lambda a:user_dict[a])\n",
    "    X = np.concatenate(list(training_data['final_data']))\n",
    "    y = np.array(training_data['label'].values)\n",
    "    return X,y,user_dict\n",
    "activity_label = 'Walking'\n",
    "window_size = 20\n",
    "base_directory = './data/mORAL_dataset_for_python_upload_09072020/'\n",
    "training_data = pickle.load(open(os.path.join(base_directory,'processed_data',activity_label,'train.p'),'rb')).sort_values('timestamp').reset_index(drop=True)\n",
    "testing_data = pickle.load(open(os.path.join(base_directory,'processed_data',activity_label,'test.p'),'rb')).sort_values('timestamp').reset_index(drop=True)\n",
    "if not os.path.isdir(os.path.join(base_directory,'results',activity_label)):\n",
    "    os.makedirs(os.path.join(base_directory,'results',activity_label))\n",
    "result_directory = os.path.join(base_directory,'results',activity_label)\n",
    "model_directory = os.path.join(result_directory,'activity_{}_window_size_new_v4_{}.h5'.format(activity_label,window_size))\n",
    "X_train,y_train,user_dict = get_X_y_dict(training_data)\n",
    "X_test,y_test,user_dict =  get_X_y_dict(testing_data,user_dict)\n",
    "trained_model = get_trained_model(X_train,y_train,n_timesteps=X_train.shape[1],n_channels=X_train.shape[-1],window_size=window_size,filepath=model_directory)\n",
    "y_pred_test = trained_model.predict(X_test)\n",
    "testing_data['embedding'] = list(y_pred_test[0])\n",
    "testing_data['prediction'] = list(y_pred_test[0].argmax(axis=1))\n",
    "print(accuracy_score(testing_data['label'],testing_data['prediction']))\n",
    "pickle.dump(testing_data,open(os.path.join(result_directory,'activity_{}_window_size_new_v4_{}.p'.format(activity_label,window_size)),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(testing_data['label'],testing_data['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51b244ab9aca612e739a0539ae1af887c58db9e180d786deb0ab1761def69c1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
